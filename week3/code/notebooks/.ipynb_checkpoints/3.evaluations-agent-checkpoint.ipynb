{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6921c0d9-f87f-4b90-bcd8-b5d43a46e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e09b9fb-54d2-47be-a5fb-b501eb375f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import main\n",
    "agent = main.agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "289f2870-f043-4110-9119-f63e035693bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ground_truth = pd.read_csv('ground_truth_evidently.csv')\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9958cca2-ed63-4b6c-8f0c-428069be2be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'column type defaults Evidently', 'summary_answer': 'The article lists default column types applied during automated mapping when no explicit `DataDefinition` is provided, enhancing user understanding.', 'difficulty': 'beginner', 'intent': 'text', 'filename': 'docs/library/data_definition.mdx'}\n"
     ]
    }
   ],
   "source": [
    "q = ground_truth[10]\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c454b798-d592-4632-9a01-f22b09657596",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Evidently's Default Column Types and Configurations\n",
      "\n",
      "## Default Column Types in Evaluations\n",
      "\n",
      "In Evidently, when creating evaluations, the library uses reasonable defaults for various column types. These defaults allow users to run evaluations with minimal setup, including supporting both structured tabular data and workflows for machine learning (ML) and large language models (LLMs). The system is designed around the concept of presets that include pre-configured column types, metrics, and evaluations, making it easier for users to focus on specific analysis without requiring extensive configuration. Users can also customize these defaults based on their particular datasets and evaluation needs.\n",
      "\n",
      "### References\n",
      "\n",
      "- Evidently Overview (https://github.com/evidentlyai/docs/blob/main/faq/why_evidently.mdx)\n",
      "\n",
      "- Evaluations in Evidently (https://github.com/evidentlyai/docs/blob/main/metrics/introduction.mdx)\n",
      "\n",
      "\n",
      "\n",
      "## Configuration of Column Types\n",
      "\n",
      "Evidently allows for a modular approach to data evaluation, providing built-in capabilities for defining and configuring column types. Users can specify the types of data they are working with during evaluations, with options for auto-generating test conditions based on the injected data schema. This flexibility enables users to tailor the evaluation process according to the demands of their specific data and metrics.\n",
      "\n",
      "### References\n",
      "\n",
      "- Customization in Evidently (https://github.com/evidentlyai/docs/blob/main/faq/why_evidently.mdx)\n",
      "\n",
      "- Configurable Column Types (https://github.com/evidentlyai/docs/blob/main/metrics/introduction.mdx)\n",
      "\n",
      "\n",
      "\n",
      "## Usage of Presets and Reasonable Defaults\n",
      "\n",
      "When utilizing Evidently, users benefit from the library's presets and reasonable defaults feature, which empowers them to conduct evaluations with little initial input. The platform's design caters to both technical (via API) and non-technical (via a no-code interface) users. This design philosophy enhances usability across different user skills while ensuring that evaluations are robust and comprehensive.\n",
      "\n",
      "### References\n",
      "\n",
      "- Modular Design and Usability (https://github.com/evidentlyai/docs/blob/main/faq/why_evidently.mdx)\n",
      "\n",
      "- Overview of Built-In Evaluations (https://github.com/evidentlyai/docs/blob/main/metrics/introduction.mdx)\n",
      "\n",
      "\n",
      "\n",
      "## All References\n",
      "\n",
      "- Getting Started with Evidently Cloud (docs/setup/cloud.mdx)\n",
      "\n",
      "- Understanding Evidently's Functional Features (faq/why_evidently.mdx)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test agent with simple question: \n",
    "\n",
    "result = await agent.run(q['question'])\n",
    "print(result.output.format_article())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ff907f-66d4-4ef2-b29b-0226764d7fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 50 questions to work with instead of entire dataset\n",
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "ground_truth_sample = random.sample(ground_truth, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6513aa3b-85c4-4176-96f1-de539ca70402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sample\n",
    "import pickle\n",
    "\n",
    "with open('sample.bin', 'wb') as f_out:\n",
    "    pickle.dump(ground_truth_sample, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e551539-995b-496b-8855-2b40fb0aec7d",
   "metadata": {},
   "source": [
    "The plan is to evaluate the agent against all ground truth data.\n",
    "\n",
    "But what if it breaks while evaluating? It'd be pity if at 80% it breaks with a network error (timeout or something like that), and we need to re-run the whole thing .\n",
    "\n",
    "So let's put things into a try/except block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a01aae8-f356-415e-833b-f17f3bad31c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "async def run_agent(q):\n",
    "    try:\n",
    "        result = await agent.run(q['question'])\n",
    "        return (q, result)\n",
    "    except:\n",
    "        print(f'error processing {q}')\n",
    "        traceback.print_exc()\n",
    "        return (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de45647-990c-4731-9b3e-6858cbe7c64c",
   "metadata": {},
   "source": [
    "### Parallel Processing Setup\n",
    "\n",
    "To efficiently process multiple queries, we'll use asynchronous processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a07cc7b3-ceb4-4060-abd2-1f9f705b1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "async def map_progress(seq, f, max_concurrency=6):\n",
    "    \"\"\"Asynchronously map async function f over seq with progress bar.\"\"\"\n",
    "    semaphore = asyncio.Semaphore(max_concurrency)\n",
    "\n",
    "    async def run(el):\n",
    "        async with semaphore:\n",
    "            return await f(el)\n",
    "\n",
    "    # create one coroutine per element\n",
    "    coros = [run(el) for el in seq]\n",
    "\n",
    "    # turn them into tasks that complete as they finish\n",
    "    completed = asyncio.as_completed(coros)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for coro in tqdm(completed, total=len(seq)):\n",
    "        result = await coro\n",
    "        results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b8f74-e2dc-4b8b-bba1-62eedd0a45fc",
   "metadata": {},
   "source": [
    "### Initial evanuation of sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93c333b1-35fa-4cc3-8612-71695b692628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ff06663d834c36b69f31b1844770d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'validating SQL syntax', 'summary_answer': 'Lists the IsValidSQL() function, which validates if submitted SQL queries are syntactically correct without executing them.', 'difficulty': 'intermediate', 'intent': 'code', 'filename': 'metrics/all_descriptors.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 194242, Requested 22673. Please try again in 5.074s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_17052/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 194242, Requested 22673. Please try again in 5.074s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'using trace_event decorator', 'summary_answer': 'You can use the `trace_event` decorator to collect traces for specific functions, with examples provided for logging various function arguments.', 'difficulty': 'beginner', 'intent': 'code', 'filename': 'docs/platform/tracing_setup.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 194752, Requested 30288. Please try again in 7.512s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_17052/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 194752, Requested 30288. Please try again in 7.512s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'automatic column mapping Evidently', 'summary_answer': 'The article details how to use an empty `DataDefinition()` for automatic mapping of columns by type and name when creating a `Dataset` object.', 'difficulty': 'intermediate', 'intent': 'text', 'filename': 'docs/library/data_definition.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 192034, Requested 15249. Please try again in 2.184s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_17052/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 192034, Requested 15249. Please try again in 2.184s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'data drift monitoring evidently', 'summary_answer': 'The Evidently library includes features to detect data drift, allowing users to monitor changes in data distribution and maintain model reliability.', 'difficulty': 'intermediate', 'intent': 'code', 'filename': 'docs/library/overview.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 15685. Please try again in 4.705s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_17052/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 15685. Please try again in 4.705s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'Evidently Dataset setup example', 'summary_answer': 'It provides a step-by-step setup for creating a `Dataset` object using a `DataDefinition`, including code snippets to guide implementation.', 'difficulty': 'beginner', 'intent': 'code', 'filename': 'docs/library/data_definition.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 249. Please try again in 74ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_17052/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 249. Please try again in 74ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'importance of precision-recall curve', 'summary_answer': 'The article elaborates on the precision-recall curve and its relevance in understanding the balance between precision and recall for different classification thresholds.', 'difficulty': 'beginner', 'intent': 'text', 'filename': 'metrics/explainer_classification.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 250. Please try again in 75ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_17052/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 250. Please try again in 75ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    }
   ],
   "source": [
    "all_results = await map_progress(ground_truth_sample, run_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c991f5c7-fbc8-447a-ae8c-4558d3dab2f6",
   "metadata": {},
   "source": [
    "### Processing Results for Analysis\n",
    "\n",
    "When we run it on many queries, we can spot some problems. For example, for some queries the agent is making too many search queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e611ff1c-70dc-4a66-bd5d-b712fa374fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a helper functions to simplify the message structure\n",
    "\n",
    "import json\n",
    "\n",
    "def simplify_messages(messages):\n",
    "    messages_simplified = []\n",
    "\n",
    "    for m in messages:\n",
    "        parts = []\n",
    "\n",
    "        for original_part in m.parts:\n",
    "            kind = original_part.part_kind\n",
    "            # print(original_part)\n",
    "            part = {\n",
    "                'kind': kind\n",
    "            }\n",
    "            if kind == 'user-prompt':\n",
    "                part['content'] = original_part.content\n",
    "            if kind == 'tool-call':\n",
    "                if original_part.tool_name == 'final_result':\n",
    "                    continue\n",
    "    \n",
    "                part['tool_name'] = original_part.tool_name\n",
    "                part['args'] = json.loads(original_part.args)\n",
    "            if kind == 'tool-return':\n",
    "                continue\n",
    "            if kind == 'text':\n",
    "                part['content'] = original_part.content\n",
    "\n",
    "            parts.append(part)\n",
    "\n",
    "        if len(parts) > 0:\n",
    "            messages_simplified.extend(parts)\n",
    "\n",
    "    return messages_simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83b89a5e-67eb-4d72-a136-b5fa81cf4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's count the number of tool calls to understand agent behavior\n",
    "\n",
    "def count_tool_calls(messages):\n",
    "    cnt = 0 \n",
    "    for m in messages:\n",
    "        if m['kind'] == 'tool-call':\n",
    "            cnt = cnt + 1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b5654b4-a2da-4aeb-a36c-9f5f0359b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process all the records\n",
    "\n",
    "def process_result(q, result):\n",
    "    row = {}\n",
    "\n",
    "    row['question'] = q['question']\n",
    "    row['answer'] = result.output.format_article()\n",
    "    row['messages'] = simplify_messages(result.new_messages())\n",
    "    row['num_tool_calls'] = count_tool_calls(row['messages']) \n",
    "\n",
    "    row['original_question'] = q\n",
    "    row['original_result'] = result\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "for q, result in all_results:\n",
    "    if result is None:\n",
    "        continue\n",
    "\n",
    "    row = process_result(q, result)\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ae34333-684c-4237-83fa-760485cd2317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60567f2-a744-4925-84b3-505727b9d3f9",
   "metadata": {},
   "source": [
    "### Identifying Performance Issues\n",
    "\n",
    "During our analysis, we discovered a problem: When it can't find something, it keeps searching and searching.\n",
    "\n",
    "We need to stop it and just explicitly say: \"can't find the information you're asking\". To address it, we'll ask it to limit search to 6 queries. If it can't find anything, then we'll ask it to just say it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
