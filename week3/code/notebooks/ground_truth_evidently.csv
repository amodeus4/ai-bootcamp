question,summary_answer,difficulty,intent,filename
data definition in Evidently,The article describes how to create a `DataDefinition` object to map column types and roles essential for data evaluation in Evidently.,beginner,text,docs/library/data_definition.mdx
Evidently Dataset setup example,"It provides a step-by-step setup for creating a `Dataset` object using a `DataDefinition`, including code snippets to guide implementation.",beginner,code,docs/library/data_definition.mdx
mapping column roles in Evidently,"The article explains how to define column roles like target, prediction, and id in `DataDefinition` for proper data evaluation.",intermediate,text,docs/library/data_definition.mdx
Evidently create DataDefinition example,An example is provided to show how to create and use a `DataDefinition` for mapping different column types in a dataset.,beginner,code,docs/library/data_definition.mdx
automatic column mapping Evidently,The article details how to use an empty `DataDefinition()` for automatic mapping of columns by type and name when creating a `Dataset` object.,intermediate,text,docs/library/data_definition.mdx
pandas DataFrame to Dataset,"It explains how to convert a pandas DataFrame to a Dataset object in Evidently, highlighting the importance of a proper `DataDefinition` mapping.",intermediate,code,docs/library/data_definition.mdx
different column types mapping,"The article outlines how to map various column types like numerical, categorical, and text in the `DataDefinition`, essential for evaluations.",beginner,text,docs/library/data_definition.mdx
specify text columns Evidently,"It provides guidance on specifying text columns in `DataDefinition` for LLM evaluations, including code examples.",intermediate,code,docs/library/data_definition.mdx
exclusions in DataDefinition mapping,"The article points out that columns excluded during mapping will not be considered in evaluations, emphasizing the significance of careful mapping.",intermediate,text,docs/library/data_definition.mdx
regression mapping in Evidently,"Guidance is provided on how to set up regression checks in `DataDefinition`, including how to define target and prediction columns.",advanced,code,docs/library/data_definition.mdx
column type defaults Evidently,"The article lists default column types applied during automated mapping when no explicit `DataDefinition` is provided, enhancing user understanding.",beginner,text,docs/library/data_definition.mdx
text data evaluation descriptors,"Descriptors are a universal interface for evaluating text data, allowing you to compute scores or labels for each row in your dataset.",beginner,text,docs/library/descriptors.mdx
how to create descriptors for text,You can create descriptors using built-in options or define custom ones using Python functions or LLM prompts to evaluate text data.,beginner,code,docs/library/descriptors.mdx
Python code for text descriptors,The article provides Python code snippets to import necessary modules and create descriptors for evaluating text datasets.,beginner,code,docs/library/descriptors.mdx
using LLM for text evaluation,You can use built-in LLM-based descriptors to evaluate text and return scores or labels based on external language model outputs.,intermediate,code,docs/library/descriptors.mdx
exporting results from descriptors,"Results from evaluations with descriptors can be exported or summarized, allowing for further analysis or reporting.",intermediate,code,docs/library/descriptors.mdx
text statistics descriptors,"Descriptors can compute various text statistics, allowing for detailed evaluations of responses and their content.",beginner,text,docs/library/descriptors.mdx
combine multiple descriptors,You can easily combine multiple descriptors in your evaluations to set complex pass/fail conditions for your text data.,intermediate,code,docs/library/descriptors.mdx
customizing text descriptors,"Customizing descriptors allows for tailored evaluations, enabling you to add aliases and specific parameters to meet your needs.",intermediate,code,docs/library/descriptors.mdx
descriptor tests for text data,"You can define pass/fail checks for your text data using Descriptor Tests, as detailed in the article, to enhance the evaluation process.",advanced,code,docs/library/descriptors.mdx
previewing descriptor results,"The article shows how to preview results through a DataFrame, providing a clear visual of the evaluation output.",beginner,code,docs/library/descriptors.mdx
code for adding descriptors to dataset,"The article includes code examples for adding descriptors to a Dataset object, essential for evaluating text data correctly.",beginner,code,docs/library/descriptors.mdx
implementing custom evals in Python,"You can implement custom evaluations as Python functions, providing flexibility in how text data is assessed.",advanced,code,docs/library/descriptors.mdx
evidently eval workflow setup,"The article explains how to set up and run an evaluation workflow using the Evidently library, including connecting to Evidently Cloud or running locally.",beginner,text,docs/library/evaluations_overview.mdx
create Dataset object in evidently,It provides guidance on how to create a Dataset object with the 'DataDefinition()' method to specify column roles and types within the Evidently library.,intermediate,code,docs/library/evaluations_overview.mdx
run report in evidently,"In this article, you can find instructions on how to run a report on the evaluation data using the Evidently library, including code examples.",beginner,code,docs/library/evaluations_overview.mdx
generate metrics with evidently,"The article explains how to use the evidently library to generate multiple metrics from datasets using metric generator functions, simplifying analysis.",beginner,code,docs/library/metric_generator.mdx
apply ValueDrift to all columns,It provides code examples for applying the ValueDrift metric to either all columns or specific columns in a dataset using the evidently library.,intermediate,code,docs/library/metric_generator.mdx
export evaluation results formats,"The article discusses how to export evaluation results in multiple formats such as HTML, JSON, and Python dictionaries.",beginner,text,docs/library/output_formats.mdx
save report as HTML Evidently,"You can save an evaluation report as an HTML file using the `my_report.save_html(""file.html"")` command to share or view it in a browser.",beginner,code,docs/library/output_formats.mdx
export results JSON format,"The article provides instructions on exporting evaluation results in JSON format, which is useful for storage and further processing.",beginner,code,docs/library/output_formats.mdx
generate report JSON example,"To generate a report in JSON format, use `my_report.json()` for viewing and `my_report.save_json(""file.json"")` for saving.",intermediate,code,docs/library/output_formats.mdx
output formats in Evidently explanation,The article gives a detailed overview of different output formats available in Evidently for exporting evaluation results and their uses.,intermediate,text,docs/library/output_formats.mdx
use Python dictionary for reports,"You can convert the evaluation report to a Python dictionary with `my_report.dict()`, which helps in automated evaluations in data pipelines.",advanced,code,docs/library/output_formats.mdx
evidently library core concepts,"The article provides an overview of the core concepts and components of the Evidently Python library, focusing on AI system evaluation and monitoring workflows.",beginner,text,docs/library/overview.mdx
how to use evidently for data evaluation,"Evidently allows users to run evaluations on AI system inputs and outputs with 100+ built-in metrics, making it easy to assess data quality and system performance.",beginner,code,docs/library/overview.mdx
evidently library metrics examples,"The article discusses various metrics available in the Evidently library, including checks for text quality, LLM outputs, data quality, and classification metrics, with usage examples.",intermediate,code,docs/library/overview.mdx
export evidently evaluation scores,"You can export evaluation results from the Evidently library in various formats, including JSON, Python dictionaries, or as DataFrames for further analysis.",beginner,code,docs/library/overview.mdx
LLM evaluation with evidently,"Evidently provides specific tools and workflows for evaluating large language models (LLMs), including metrics and report generation for LLM outputs.",intermediate,text,docs/library/overview.mdx
synthetic data generation evidently,"Evidently includes features for generating structured synthetic data, particularly for testing and validating AI applications, using configurable templates.",beginner,code,docs/library/overview.mdx
visual report generation evidently,"The library allows users to create visual reports in Jupyter or export them as HTML, providing a clear view of evaluation results and metrics.",beginner,code,docs/library/overview.mdx
evidently dataset object creation,"To run evaluations, create a Dataset object that holds your data and metadata, necessary for processing within the Evidently framework.",intermediate,code,docs/library/overview.mdx
descriptor usage in evidently,"Descriptors are row-level assessments used in the Evidently library to evaluate text quality, essential for analyzing LLM outputs or evaluating dataset performance.",intermediate,text,docs/library/overview.mdx
tracking evaluation results evidently,"Evidently includes a lightweight UI to track and visualize evaluation results over time, helping users monitor performance and quality metrics.",beginner,text,docs/library/overview.mdx
testing suite configuration evidently,"The article explains how to set up test suites in Evidently, which allow users to validate metrics against specific conditions during evaluations.",advanced,code,docs/library/overview.mdx
data quality checks evidently,"Evidently provides various built-in checks for assessing data quality, such as missing values, duplicates, and ranges, crucial for maintaining data integrity.",beginner,code,docs/library/overview.mdx
evidently test conditions,"The library supports defining test conditions to validate results and ensure metrics meet specified expectations, enhancing evaluation reliability.",advanced,code,docs/library/overview.mdx
metrics for classification evidently,"Evidently includes various metrics for evaluating classification tasks, such as accuracy, precision, and ROC AUC, with integrated debugging plots.",intermediate,code,docs/library/overview.mdx
data drift monitoring evidently,"The Evidently library includes features to detect data drift, allowing users to monitor changes in data distribution and maintain model reliability.",intermediate,code,docs/library/overview.mdx
integration with evidently platform,"Users can integrate Evidently evaluations with the Evidently Platform for enhanced tracking, comparison, and alerting on AI performance metrics.",intermediate,text,docs/library/overview.mdx
evidently reports generation,"The library allows for the generation of structured reports which summarize evaluations, including metrics and tests results over datasets.",beginner,code,docs/library/overview.mdx
prompt optimization tools in evidently,"Evidently includes tools for automated prompt optimization, leveraging evaluation capabilities to improve prompt effectiveness for LLMs.",intermediate,text,docs/library/overview.mdx
configuring evidently workflows,"The article provides guidance on building customized workflows using Evidently, from independent analytical processes to integrated platform monitoring.",advanced,text,docs/library/overview.mdx
presets in evidently for evaluations,Evidently supports predefined presets that simplify the evaluation process by bundling related metrics for quick assessments.,intermediate,code,docs/library/overview.mdx
evidently cloud features,"The Evidently Cloud offers additional capabilities like managed evaluations and synthetic data generation, extending the library's functionalities for users.",beginner,text,docs/library/overview.mdx
generate report with Evidently,"The article provides a comprehensive guide on generating reports in Evidently, covering both single and multiple datasets with examples.",beginner,code,docs/library/report.mdx
Evidently report presets,It explains how to use pre-built report presets to quickly generate reports and the steps to customize and combine metrics for custom reports.,beginner,text,docs/library/report.mdx
how to limit columns in Evidently report,"Details how to specify which columns to include in a report when using Evidently's preset metrics, with code snippets for clarity.",intermediate,code,docs/library/report.mdx
comparing report results Evidently,"The article demonstrates how to compare multiple evaluation results side-by-side using Evidently's compare function, including example code.",advanced,code,docs/library/report.mdx
add metadata to evaluations Evidently,The article outlines how to include metadata and tags in evaluations to improve searchability and filtering of reports in the Evidently platform.,beginner,text,docs/library/tags_metadata.mdx
custom tags example Evidently,It includes code examples for passing custom tags and metadata to Reports for better organization and tracking of evaluation runs in the Evidently framework.,intermediate,code,docs/library/tags_metadata.mdx
running tests in evidently,"The article provides details on how to run Tests in the Evidently library, highlighting auto-generated conditions and manual setups.",beginner,code,docs/library/tests.mdx
evidently tests examples,"The article includes code snippets showing how to implement Tests using Evidently, both with defaults and custom conditions.",beginner,code,docs/library/tests.mdx
conditional checks in data validation,It describes how to perform conditional checks to validate data conditions and ensure quality in datasets.,intermediate,text,docs/library/tests.mdx
how to create custom tests evidently,Guidance on defining custom tests with specific conditions like min or max value checks is provided in the article.,intermediate,code,docs/library/tests.mdx
test presets evidently,"The article explains the concept of Test Presets, which allow for quick validation setups without manually defining tests.",beginner,text,docs/library/tests.mdx
using heuristics for tests evidently,Details about how to implement tests using built-in heuristics when no reference dataset is provided are discussed.,intermediate,text,docs/library/tests.mdx
multi-condition tests evidentlly,It demonstrates how to set up multiple conditions for a single metric within the Evidently framework.,advanced,code,docs/library/tests.mdx
passing conditions for evident tests,"Explains how to define passing conditions for tests using parameters like greater than or equal, and equal.",intermediate,code,docs/library/tests.mdx
reference dataset in evidently tests,The article discusses how to use a reference dataset to set conditions for testing and the implications of comparison.,advanced,text,docs/library/tests.mdx
set up alerts in Evidently,The article explains how to set up alerts in Evidently by configuring notification channels and conditions based on tests or metrics.,beginner,code,docs/platform/alerts.mdx
Evidently alerts notification channels,"It describes various notification channels available for alerts, including Email, Slack, and Discord.",beginner,text,docs/platform/alerts.mdx
Evidently alert conditions,The document outlines how to establish alert conditions based on failed tests or specific metric values.,intermediate,code,docs/platform/alerts.mdx
manage alert fatigue Evidently,The article suggests using the `is_critical` parameter to minimize alert fatigue by designating non-critical tests as warnings.,intermediate,text,docs/platform/alerts.mdx
Evidently alert configuration examples,"Examples of configuring alerts in Evidently for different scenarios, such as test failures and metric thresholds, are provided.",advanced,code,docs/platform/alerts.mdx
add dashboard panels python,"The article provides guidance on adding panels to dashboards using the Python API, including specific code examples for different panel types.",beginner,code,docs/platform/dashboard_add_panels.mdx
evidently dashboard panel types,"It covers various panel types that can be added to the dashboard, including text, counters, pies, line, and bar charts, along with implementation details.",beginner,text,docs/platform/dashboard_add_panels.mdx
how to create a new tab in dashboard,"You can create a new tab in the dashboard using the `add_tab` method in the Python API, with a simple code example provided in the article.",beginner,code,docs/platform/dashboard_add_panels.mdx
delete dashboard tab python,"The article explains how to delete a tab using the `delete_tab` method in the Python API, complete with code examples for clarity.",intermediate,code,docs/platform/dashboard_add_panels.mdx
multiple panels in one dashboard,"You can add multiple panels to a dashboard at once, and the article explains how to do this with clear code snippets.",beginner,code,docs/platform/dashboard_add_panels.mdx
panel metrics in evidently,"The article discusses how to reference and display specific metrics in panels using the `PanelMetric` class, crucial for proper configuration.",intermediate,text,docs/platform/dashboard_add_panels.mdx
clear all panels in dashboard,"To clear all panels and tabs in a dashboard, you can use the `clear_dashboard` method, as detailed in the article.",intermediate,code,docs/platform/dashboard_add_panels.mdx
text-only panels in dashboard,It mentions how to create text-only panels perfect for titles and provides a code example for adding them to a specific tab.,beginner,code,docs/platform/dashboard_add_panels.mdx
configuring panel values,The article covers how to configure panel values and highlights the importance of referencing the appropriate metrics and labels.,advanced,text,docs/platform/dashboard_add_panels.mdx
add pie chart panel python,"You can add pie chart panels using the Python API, and the article provides a code example to demonstrate this implementation.",intermediate,code,docs/platform/dashboard_add_panels.mdx
evidently dashboard panel options,"A summary table of all panel parameters is included, describing required and optional attributes for dashboard panels.",intermediate,text,docs/platform/dashboard_add_panels.mdx
how to delete a dashboard panel,"The article explains how to delete specific panels from the dashboard using the `delete_panel` method, illustrated with code.",beginner,code,docs/platform/dashboard_add_panels.mdx
panel options and parameters,"It provides a detailed overview of all parameters for configuring panels, including size, title, and plot settings, with examples.",advanced,text,docs/platform/dashboard_add_panels.mdx
create dashboard panel examples,The article provides a step-by-step guide on how to create various types of panels such as line plots and pie charts for your dashboard.,beginner,code,docs/platform/dashboard_add_panels_ui.mdx
how to add tabs to dashboard,"Instructions are given for adding multiple tabs to the dashboard, making it easier to organize the panels you create.",beginner,code,docs/platform/dashboard_add_panels_ui.mdx
dashboard editing mode functions,The article explains the functions available in the Edit mode for managing tabs and panels on your dashboard.,intermediate,text,docs/platform/dashboard_add_panels_ui.mdx
configuring metrics for panels,Details are provided on how to select specific metrics and configure their display properties when adding panels to the dashboard.,advanced,code,docs/platform/dashboard_add_panels_ui.mdx
creating a dashboard in Evidently,"The article outlines that to create a Dashboard in Evidently, you must run an evaluation, save at least one Report to your Project, and then you can start adding Panels to visualize the data.",beginner,code,docs/platform/dashboard_overview.mdx
dashboard panels types and examples,"Dashboard Panels can be various types such as counters, line plots, and bar plots, and users can add or customize these Panels using either the Python API or the UI, as explained in the article.",intermediate,code,docs/platform/dashboard_overview.mdx
what are datasets in Evidently,"The article defines datasets as collections of data used for analysis and automated checks, highlighting their importance in the Evidently Platform.",beginner,text,docs/platform/datasets_overview.mdx
upload csv dataset Evidently Python,It explains how to upload CSV files directly or via the Python API to create datasets in the Evidently platform.,intermediate,code,docs/platform/datasets_overview.mdx
create and upload datasets in Evidently,The article explains how to create and upload datasets in Evidently by preparing them with the necessary data definitions and using methods like `add_dataset`.,beginner,code,docs/platform/datasets_workflow.mdx
how to download dataset from Evidently,Instructions for downloading datasets stored on the Evidently platform using the `load_dataset` method are provided in the article.,intermediate,code,docs/platform/datasets_workflow.mdx
run evals API example,"The article provides a simple code example for running evaluations using the Evidently API, demonstrating how to set up and execute an evaluation report.",beginner,code,docs/platform/evals_api.mdx
evidently upload evaluation results process,"It details the steps to upload evaluation results to the Evidently platform, including options for including raw data and metrics.",intermediate,text,docs/platform/evals_api.mdx
view and compare evaluation results,"The article explains how to access and compare evaluation results, allowing users to analyze multiple reports and identify performance differences.",beginner,code,docs/platform/evals_explore.mdx
no code data evaluation setup,"The article outlines how to set up data evaluations in a no-code interface, focusing on uploading datasets and choosing evaluation methods.",beginner,code,docs/platform/evals_no_code.mdx
how to use descriptors in no code,"It explains how to add descriptors for evaluations, which are essential for labeling and scoring texts within the interface.",beginner,code,docs/platform/evals_no_code.mdx
configure sentiment analysis no code,"The article provides steps on configuring sentiment analysis as a model-based evaluation method, including selecting columns and evaluation criteria.",intermediate,code,docs/platform/evals_no_code.mdx
LLM evaluator integration details,"It discusses how to integrate LLMs as judges in evaluations, including adding tokens and setting parameters for custom criteria.",advanced,text,docs/platform/evals_no_code.mdx
evals platform overview,"The article gives a comprehensive overview of running evaluations using the Evidently platform, detailing different use cases and how to implement them.",beginner,text,docs/platform/evals_overview.mdx
run evaluations Python Evidently,"You can conduct evaluations in Python on the Evidently platform by generating reports, and the article explains how to upload results and utilize the Explore feature for comparison.",intermediate,code,docs/platform/evals_overview.mdx
evidently batch evaluation example,"The article provides a simple example of running batch evaluations using the Evidently library, showing how to connect datasets and generate reports for statistical analysis.",beginner,code,docs/platform/monitoring_local_batch.mdx
workflow for batch monitoring,"The article details the complete workflow for batch monitoring, including configuring metrics, running evaluations, and setting up dashboards for tracking results over time.",intermediate,text,docs/platform/monitoring_local_batch.mdx
AI quality monitoring explained,"The article outlines how AI observability helps evaluate input and output quality in production applications, providing tools and strategies for effective monitoring.",beginner,text,docs/platform/monitoring_overview.mdx
set up batch monitoring with Evidently,"It details how to establish batch monitoring jobs using the Evidently platform, including creating evaluation pipelines and running metric calculations.",intermediate,code,docs/platform/monitoring_overview.mdx
Using Tracely library for AI monitoring,The article describes how to instrument applications with the Tracely library to capture detailed operational data and schedule evaluations efficiently.,advanced,code,docs/platform/monitoring_overview.mdx
Evidently Platform features summary,"The article highlights key features of the Evidently Platform, including local evaluations, dataset management, synthetic data generation, regression testing, monitoring, and tracing capabilities.",beginner,text,docs/platform/overview.mdx
Evidently Python library examples,"The article provides insights into using the Evidently Python library for running local evaluations and uploading datasets, along with descriptions of its functionalities.",intermediate,code,docs/platform/overview.mdx
create project in Evidently,"To create a project in Evidently, use the `create_project` method in Python, specifying the project name and optionally the organization ID.",beginner,code,docs/platform/projects_manage.mdx
manage projects Evidently UI,"In the Evidently UI, users can create or edit projects by using the interface options on the home page, including a 'plus' sign for new projects and hover actions for editing existing ones.",beginner,text,docs/platform/projects_manage.mdx
delete project in Evidently Python,"To delete a project in Python, use the `ws.delete_project(""PROJECT ID"")` method, remembering that this will delete all associated data.",intermediate,code,docs/platform/projects_manage.mdx
project parameters in Evidently,"Each project in Evidently has parameters like name, ID, description, and dashboard configuration that can be adjusted for monitoring purposes.",advanced,text,docs/platform/projects_manage.mdx
what is a project in evidently,"A Project in Evidently helps organize data and evaluations for specific use cases and includes datasets, reports, and traces.",beginner,text,docs/platform/projects_overview.mdx
evidently project structure guidelines,"The article suggests structuring Projects based on application or model, app components, test scenarios, development phases, or use cases for better organization.",intermediate,code,docs/platform/projects_overview.mdx
evidently python api project management,"You can connect to Projects via the Python API to send data, edit dashboards, and manage configurations, making integration straightforward.",advanced,code,docs/platform/projects_overview.mdx
LLM tracing overview,"The article explains LLM tracing as a way to collect detailed performance data for AI applications, which is crucial for evaluation and analysis.",beginner,text,docs/platform/tracing_overview.mdx
how to implement tracing in Evidently,It discusses how to instrument your AI application using the Tracely library to capture execution data for detailed analysis.,intermediate,code,docs/platform/tracing_overview.mdx
tracing features in Evidently,The overview highlights the Pro features of Evidently Cloud and Evidently Enterprise that include tracing capabilities.,beginner,text,docs/platform/tracing_overview.mdx
using Tracely for AI tracing,The article covers the use of the open-source Tracely library based on OpenTelemetry for tracing LLM applications.,intermediate,code,docs/platform/tracing_overview.mdx
is tracing always necessary for LLMs,Tracing is optional in the Evidently platform but is recommended for deeper insights into LLM execution flows.,beginner,text,docs/platform/tracing_overview.mdx
evaluating tracing data with Evidently,"Once data is captured, the article explains how to run evaluations on the tracing datasets for better performance insights.",intermediate,code,docs/platform/tracing_overview.mdx
install tracely package,You need to install the `tracely` package from PyPi using `pip install tracely` to begin tracing.,beginner,code,docs/platform/tracing_setup.mdx
init_tracing function example,"The article provides an example of how to initialize tracing with the `init_tracing` function, including necessary parameters like `address` and `api_key`.",intermediate,code,docs/platform/tracing_setup.mdx
tracely parameters explained,"The article includes a detailed table explaining the parameters for the `init_tracing()` function, such as `address`, `api_key`, and `project_id`.",intermediate,text,docs/platform/tracing_setup.mdx
using trace_event decorator,"You can use the `trace_event` decorator to collect traces for specific functions, with examples provided for logging various function arguments.",beginner,code,docs/platform/tracing_setup.mdx
get_info function to retrieve export_id,"To retrieve the `export_id` of the tracing dataset, you can call the `get_info()` function after initializing tracely.",intermediate,code,docs/platform/tracing_setup.mdx
nested events in tracing,The article discusses how to trace multi-step workflows by using the `@trace_event` decorator for nested function calls within a single parent trace.,advanced,text,docs/platform/tracing_setup.mdx
context manager for tracing,"You can create trace events without decorators by using the context manager `create_trace_event`, allowing for tracing inline code effectively.",intermediate,code,docs/platform/tracing_setup.mdx
set result for trace event,The article mentions how to set results for trace events using methods like `set_result` within the `event` object in a tracing context.,intermediate,code,docs/platform/tracing_setup.mdx
session_id for separate traces,"Using a shared `session_id`, you can join traces created in separate functions or threads for better tracking of related events.",advanced,text,docs/platform/tracing_setup.mdx
bind_to_trace example,The article provides a code example of how to use `tracely.bind_to_trace` to link events into a single trace using a unique `trace_id`.,advanced,code,docs/platform/tracing_setup.mdx
create Evidently Cloud account,The article explains how to sign up for a free Evidently Cloud account and create an organization after logging in.,beginner,text,docs/setup/cloud.mdx
self-host Evidently UI,"The article explains the steps to self-host the Evidently UI service, including the creation of a local or remote workspace.",beginner,text,docs/setup/self-hosting.mdx
create a local workspace Evidently,It details how to create a local workspace for storing evaluation results and running the UI service on your machine.,beginner,code,docs/setup/self-hosting.mdx
Evidently UI launch command,"Instructions for launching the Evidently UI service through terminal commands are provided, outlining different options based on workspace locations.",intermediate,code,docs/setup/self-hosting.mdx
Evidently remote workspace setup,"The setup for a remote workspace is described, including necessary imports and how to specify the remote service URL.",intermediate,code,docs/setup/self-hosting.mdx
delete workspace command Evidently,The article provides a warning about how to delete a workspace and emphasizes the importance of data backup before executing the command.,advanced,text,docs/setup/self-hosting.mdx
evidently github actions integration,The article explains how to integrate Evidently with GitHub Actions to automatically test LLM outputs during continuous integration.,beginner,text,examples/GitHub_actions.mdx
ci cd testing llm with evidently,"Learn how to set up CI/CD testing for your LLM using Evidently in conjunction with GitHub Actions, ensuring reliable performance with every code push.",beginner,code,examples/GitHub_actions.mdx
how to configure evidently tests in github actions,"The article outlines the steps required to configure testing for your LLM outputs in GitHub Actions using Evidently, including defining test datasets and evaluation methods.",intermediate,code,examples/GitHub_actions.mdx
evidently report metrics,"This article provides insights into how Evidently generates detailed test reports with pass/fail metrics for LLM outputs, which helps in tracking performance.",intermediate,text,examples/GitHub_actions.mdx
advanced evidently testing strategies,"For those familiar with Evidently, the article suggests advanced methods for integrating detailed testing strategies within a GitHub Actions workflow.",advanced,code,examples/GitHub_actions.mdx
basic LLM evaluation methods,"The article outlines different LLM evaluation methods, starting with the basics of setting up an evaluation API.",beginner,text,examples/LLM_evals.mdx
code example for LLM evaluation API,"It includes a tutorial with code examples for implementing various LLM evaluation methods, accessible via an open notebook.",intermediate,code,examples/LLM_evals.mdx
LLM judge creation tutorial,The article provides a comprehensive tutorial on how to create and evaluate an LLM judge for assessing text responses using custom criteria and reference comparisons.,beginner,code,examples/LLM_judge.mdx
evaluate responses with LLM,It explains how to use LLMs to evaluate responses either by comparing them to a reference or by using custom criteria for assessment.,beginner,code,examples/LLM_judge.mdx
install Evidently Python package,Instructions for installing the Evidently library using pip are provided to get started with the tutorial.,beginner,code,examples/LLM_judge.mdx
LLM as judge examples,Examples are included in the article to illustrate how to implement an LLM as a judge for evaluating text responses based on specified criteria.,beginner,code,examples/LLM_judge.mdx
creating evaluation datasets,The article describes how to create a toy Q&A dataset that can be used to test the LLM judge's performance.,beginner,code,examples/LLM_judge.mdx
LLM evaluator prompt design,It covers how to design effective prompts for the LLM evaluator to ensure accurate evaluations of responses.,intermediate,code,examples/LLM_judge.mdx
how to evaluate LLM judge performance,The article highlights techniques for evaluating the performance and accuracy of the LLM judge by comparing its outputs to manual labels.,intermediate,code,examples/LLM_judge.mdx
how to use BinaryClassificationPromptTemplate,It includes details on how to configure the BinaryClassificationPromptTemplate to set up criteria for evaluating responses as correct or incorrect.,intermediate,code,examples/LLM_judge.mdx
Jupyter notebook LLM judge,Guidance on using Jupyter notebooks for executing the code examples and rendering evaluation results directly is provided.,beginner,text,examples/LLM_judge.mdx
LLM evaluator tutorial steps,"The article outlines steps to create and run an LLM as a judge, including data definition and configuration for evaluations.",beginner,text,examples/LLM_judge.mdx
OpenAI API key setup,Instructions are included for setting up an OpenAI API key as an environment variable for using the LLM evaluator in code.,beginner,code,examples/LLM_judge.mdx
collecting evaluation metrics,"The tutorial explains how to collect various metrics to assess the effectiveness of the LLM judge, such as precision, recall, and accuracy.",advanced,code,examples/LLM_judge.mdx
reporting evaluation results,It describes how to generate a report summarizing the evaluation results with the Evidently library after scoring the LLM outputs.,intermediate,code,examples/LLM_judge.mdx
LLM evaluator compare new responses,The article discusses methods to compare new responses against known correct answers using the LLM as a judge.,intermediate,code,examples/LLM_judge.mdx
understanding correctness evaluator,It provides insights into the correctness evaluator setup and how it determines the accuracy of responses based on reference answers.,intermediate,text,examples/LLM_judge.mdx
verbosity evaluator setup,The tutorial includes steps for creating a verbosity evaluator to assess the conciseness of responses using LLM.,advanced,code,examples/LLM_judge.mdx
usage of custom criteria with LLM,The article explains how to apply custom evaluation criteria when using an LLM judge to assess responses.,intermediate,text,examples/LLM_judge.mdx
cloud integration with Evidently,It details how to integrate and send your evaluation results to the Evidently Cloud for further analysis and exploration.,intermediate,code,examples/LLM_judge.mdx
best practices for LLM judges,The article encourages iterating on your LLM judge's prompt and exploring different LLMs to improve evaluation accuracy.,advanced,text,examples/LLM_judge.mdx
synthetic data generation for LLM evaluations,"It mentions the capability to create synthetic datasets to facilitate LLM evaluations, enhancing testing methods for various use cases.",intermediate,text,examples/LLM_judge.mdx
evaluate output with multiple LLMs,The article explains how to use multiple LLMs to evaluate the same output and consider a result a 'pass' only if all or most approve.,beginner,code,examples/LLM_jury.mdx
install evidently for LLM,"Instructions for installing the Evidently package to work with LLMs are provided in the article, including the necessary pip commands.",beginner,code,examples/LLM_jury.mdx
set up LLM judges,The article outlines how to set up different LLMs as judges by passing their API keys and provides code snippets for setup.,beginner,code,examples/LLM_jury.mdx
aggregate evaluation results in LLM,It describes how to aggregate evaluations from multiple LLMs to determine whether generated emails are appropriate based on majority approval.,intermediate,code,examples/LLM_jury.mdx
define evaluation criteria for LLM,The article explains using a prompt template to define the criteria for evaluating appropriateness of the emails generated.,intermediate,code,examples/LLM_jury.mdx
flags for LLM disagreements,"You can add custom descriptors to flag disagreements among LLM evaluations, identifying when models do not unanimously agree.",intermediate,code,examples/LLM_jury.mdx
judges LLM output disagreement,"The article shows how to create indicators for disagreements in outputs from different LLM judges, enhancing evaluation clarity.",advanced,code,examples/LLM_jury.mdx
report LLM evaluation results,It provides steps to run a report on the evaluation results locally or upload them to Evidently Cloud for easier access.,intermediate,code,examples/LLM_jury.mdx
understand LLM evaluation metrics,"The article elaborates on various metrics that summarize LLM evaluation results, including approval rates and disagreement counts.",advanced,text,examples/LLM_jury.mdx
RAG system evaluation metrics,The article covers metrics to assess both retrieval and generation quality in RAG systems using Evidently.,beginner,text,examples/LLM_rag_evals.mdx
setting up Evidently for RAG,Instructions for installing the Evidently library and setting up the environment variables necessary for evaluation tasks are provided in the article.,beginner,code,examples/LLM_rag_evals.mdx
data evaluation example in RAG,The tutorial provides a sample code for generating synthetic datasets and evaluating their context and response quality in RAG systems.,beginner,code,examples/LLM_rag_evals.mdx
how to visualize RAG performance,The article explains how to visualize RAG system evaluations using pandas dataframes and generate structured reports for performance tracking.,intermediate,code,examples/LLM_rag_evals.mdx
pandas options for displaying dataframes,"It includes code to set pandas display options to show full-width dataframes, which is useful for reviewing evaluation outputs.",beginner,code,examples/LLM_rag_evals.mdx
evaluate retrieval quality in RAG,"Methods to assess retrieval quality in a RAG system are explained, including using specific context quality metrics in the evaluation process.",intermediate,code,examples/LLM_rag_evals.mdx
synthetic dataset creation for RAG,The article demonstrates how to create synthetic datasets tailored for testing RAG systems through example code snippets.,beginner,code,examples/LLM_rag_evals.mdx
inspecting RAG evaluation results,"Guidelines are provided for interpreting the results of RAG evaluations, focusing on both relevance and context quality.",intermediate,text,examples/LLM_rag_evals.mdx
compare generated responses against ground truth,The article outlines methods for comparing generated answers from RAG to known correct answers using various metrics like correctness and semantic similarity.,advanced,code,examples/LLM_rag_evals.mdx
uploading evaluation results to Evidently Cloud,Instructions for connecting to Evidently Cloud and uploading evaluated data for better tracking and reporting are included.,intermediate,code,examples/LLM_rag_evals.mdx
how to generate RAG performance report,The article explains how to compile evaluation metrics into a comprehensive report for analyzing system performance across multiple queries.,intermediate,code,examples/LLM_rag_evals.mdx
evaluate without ground truth in RAG,"Methods to assess RAG response quality without reference answers using LLM judges are discussed, including the Faithfulness metric.",advanced,code,examples/LLM_rag_evals.mdx
Evidently library descriptors and evaluators,The article lists and describes various descriptors and evaluators available in the Evidently library for RAG evaluations.,intermediate,text,examples/LLM_rag_evals.mdx
regression testing for LLM outputs,The article explains how to run regression tests on outputs from LLMs to compare new and old responses after changing parameters.,beginner,text,examples/LLM_regression_testing.mdx
how to create a toy dataset for testing LLMs,It guides on building a small Q&A dataset with reference answers to use for evaluating LLM performance.,beginner,code,examples/LLM_regression_testing.mdx
Evidently Cloud setup for LLM testing,Instructions are provided for setting up Evidently Cloud and running evaluations using Python and API keys.,beginner,code,examples/LLM_regression_testing.mdx
comparison of old and new LLM responses,The article illustrates processes for comparing LLM outputs before and after changes to assess for significant variations.,intermediate,text,examples/LLM_regression_testing.mdx
installing Evidently for LLM,It includes commands for installing the Evidently package necessary for running LLM evaluations in Python.,beginner,code,examples/LLM_regression_testing.mdx
create LLM evaluation reports,Instructions are provided on how to create and run reports that evaluate LLM outputs against defined metrics like correctness and style.,intermediate,code,examples/LLM_regression_testing.mdx
using OpenAI API for LLM evaluations,The tutorial details how to connect and utilize the OpenAI API for evaluating output correctness in LLM regression tests.,intermediate,code,examples/LLM_regression_testing.mdx
Writing custom LLM judges for regression testing,The article explains how to implement custom evaluators to check for correctness and style consistency in outputs from LLMs.,advanced,code,examples/LLM_regression_testing.mdx
analyzing length of LLM responses,It discusses how to set up evaluations to check if generated LLM responses meet specific length criteria.,beginner,code,examples/LLM_regression_testing.mdx
designing test suites for LLM outputs,The document elaborates on how to build test suites that help evaluate various aspects of LLM outputs like correctness and style.,intermediate,text,examples/LLM_regression_testing.mdx
monitoring LLM testing results over time,"There is guidance on creating dashboards to track results of tests, providing insights on LLM output performance over time.",intermediate,code,examples/LLM_regression_testing.mdx
data preparation for LLM regression testing,The tutorial involves creating datasets and understanding their structures to prepare for regression testing of LLM outputs.,intermediate,code,examples/LLM_regression_testing.mdx
LLM testing with Python examples,The article provides Python code examples for performing regression testing on LLM-generated outputs using Evidently framework.,beginner,code,examples/LLM_regression_testing.mdx
reporting errors in LLM outputs,It explains the process for generating reports that highlight errors in LLM outputs based on predefined metrics and conditions.,advanced,code,examples/LLM_regression_testing.mdx
setting up monitoring dashboards for LLM tests,Instructions are shared on how to set up a dashboard to visualize results from multiple LLM test runs and monitor their success rate.,intermediate,code,examples/LLM_regression_testing.mdx
detecting style mismatches in LLM responses,The article covers how to implement evaluations to check if the style of LLM outputs matches reference outputs or diverges significantly.,advanced,code,examples/LLM_regression_testing.mdx
best practices for LLM regression testing,"The document offers insights and suggestions for effectively implementing regression testing for LLM outputs, ensuring reliable performance changes.",intermediate,text,examples/LLM_regression_testing.mdx
LLM output correctness evaluation techniques,It explains various methods for evaluating the correctness of outputs generated by LLMs to ensure they are factually accurate.,advanced,text,examples/LLM_regression_testing.mdx
how to simulate LLM output generation,The tutorial describes methods for simulating the process of generating outputs with LLMs to facilitate regression testing.,intermediate,code,examples/LLM_regression_testing.mdx
overview of LLM regression testing process,"The article breaks down the overall regression testing process for LLM outputs, highlighting critical steps involved in testing.",beginner,text,examples/LLM_regression_testing.mdx
LLM evaluation tutorial examples,"The article provides end-to-end examples of evaluating LLMs, including different evaluation methods and specific workflows.",beginner,code,examples/introduction.mdx
how to use LLMs as judges,The document includes a tutorial on creating and tuning LLM judges that align with human evaluations.,intermediate,code,examples/introduction.mdx
basic ML quickstart,A quickstart guide for testing tabular data quality and data drift in machine learning is detailed in the article.,beginner,code,examples/introduction.mdx
Grafana LLM evaluation setup,"Instructions for visualizing LLM evaluation metrics with Grafana, including database integration, are provided in the article.",intermediate,code,examples/introduction.mdx
endpoint for GitHub actions,The article details how to integrate Evidently evaluations as part of a CI/CD workflow with native GitHub actions.,advanced,code,examples/introduction.mdx
start with LLM quickstart guide,New users can begin with the LLM quickstart section to learn how to evaluate the quality of text outputs.,beginner,text,examples/introduction.mdx
what is RAG evaluation,"A walkthrough of RAG evaluation metrics and methods is explained, providing insights into textual retrieval and generation quality.",intermediate,text,examples/introduction.mdx
descriptor cookbook tutorial,"The article features a descriptor cookbook that outlines different descriptors in a single notebook format, providing practical examples.",beginner,code,examples/introduction.mdx
ML metrics overview,"A comprehensive overview of various data and ML metrics, including regression, classification, quality, and drift, is presented for users.",intermediate,text,examples/introduction.mdx
examples of adversarial testing,"The document describes a tutorial for scenario-based risk testing on sensitive topics using LLMs, showcasing evaluation strategies.",advanced,code,examples/introduction.mdx
LLM judge prompt optimization,The article includes tutorials focused on optimizing prompts for LLM judges to improve classification tasks and feedback utilization.,intermediate,code,examples/introduction.mdx
complete LLM evaluation course,"A free applied course is available, covering core LLM evaluation workflows with accompanying video tutorials and code examples.",beginner,text,examples/introduction.mdx
Evidently Cloud v2 features,"The article outlines significant new features in Evidently Cloud v2, including a redesigned dashboard and improved performance, emphasizing enhancements in user experience and functionality.",beginner,text,faq/cloud_v2.mdx
Evidently migration guide,"This guide outlines how to migrate from earlier versions of the Evidently library to version 0.6 and above, highlighting key changes and new features.",beginner,text,faq/migration.mdx
changes in Evidently 0.6 API,"The migration guide explains the important changes introduced in the Evidently 0.6 API, including the introduction of a new Report object.",beginner,text,faq/migration.mdx
example of using new Report in Evidently,The article provides a code example of how to use the new Report object introduced in Evidently 0.6 for generating reports with datasets.,intermediate,code,faq/migration.mdx
how to create Dataset in Evidently,"Instructions on creating a Dataset object in Evidently with the new data_definition structure are detailed, along with code samples.",beginner,code,faq/migration.mdx
breaking changes in Evidently 0.7,"The guide highlights the breaking changes introduced in Evidently 0.7, including making the new API the default, affecting how users should import packages.",intermediate,text,faq/migration.mdx
multiple targets in Evidently Reports,"The article discusses the new functionality to handle multiple targets and predictions within the same Evidently Report, allowing for more complex analyses.",advanced,code,faq/migration.mdx
update metrics in Evidently dashboard,"It covers the changes to the Dashboard API, including updates for integrating new metrics and simplifying panel creation.",advanced,code,faq/migration.mdx
Evidently open-source features,"The article outlines that all core features of the Evidently platform are available in the open-source version, making it suitable for individual data scientists.",beginner,text,faq/oss_vs_cloud.mdx
Evidently Cloud vs Enterprise deployment,"The differences between Evidently Cloud and Enterprise include support levels, maintenance responsibilities, and additional features available in the commercial edition.",beginner,text,faq/oss_vs_cloud.mdx
Evidently library installation guide,"The Evidently library can be easily installed for running data evaluations, targeting users who need implementation details.",beginner,code,faq/oss_vs_cloud.mdx
Essential features of Evidently Cloud,"Evidently Cloud offers enhanced features compared to the OSS version, such as no-code evaluations and scheduled evaluations, suitable for teams looking for robust AI monitoring solutions.",intermediate,text,faq/oss_vs_cloud.mdx
Setting up Evidently Enterprise deployment,"The article details how to deploy the Evidently Enterprise edition in private or on-premises environments, including setup and support.",intermediate,code,faq/oss_vs_cloud.mdx
Integration challenges with Evidently OSS,"For advanced users, the article discusses potential issues and troubleshooting for integrating Evidently OSS in production environments, focusing on the need for engineering resources.",advanced,text,faq/oss_vs_cloud.mdx
evidently telemetry data collection,"The article explains that Evidently collects anonymous usage data to monitor user interaction, which helps improve the tool.",beginner,text,faq/telemetry.mdx
how to opt-out of telemetry in evidently,Users can opt-out of telemetry by setting the environment variable DO_NOT_TRACK to any value after starting the service.,beginner,code,faq/telemetry.mdx
data collected by evidently telemetry,"Telemetry data collected includes environment and service usage data, like timestamps, user IDs, and actions taken within the Evidently Monitoring UI.",beginner,text,faq/telemetry.mdx
list of actions tracked in evidently telemetry,"The article lists various actions that are tracked, such as startup, project dashboard views, and report listings to understand feature usage.",intermediate,text,faq/telemetry.mdx
enable telemetry in evidently monitoring,"Telemetry is enabled by default in Evidently Monitoring UI, with an option to disable it using a specific environment variable.",beginner,code,faq/telemetry.mdx
anonymous user data in evidently,Evidently collects only anonymous data regarding users to ensure privacy while improving tool functionality based on user interaction.,beginner,text,faq/telemetry.mdx
evidently telemetry environment data,"The telemetry includes environment data such as OS name and version, Python version, and tool version, allowing insights into user setups.",intermediate,text,faq/telemetry.mdx
correctly disabling telemetry in evidently,"To disable telemetry, set the DO_NOT_TRACK environment variable, and the service will indicate that anonymous usage reporting is disabled.",intermediate,code,faq/telemetry.mdx
importance of telemetry in open-source tools,"The article highlights that keeping telemetry on helps developers understand usage patterns, prioritize features, and improve the tool based on actual usage data.",advanced,text,faq/telemetry.mdx
examples of event logs in evidently telemetry,"Event logs are presented in the article, showcasing structured data for actions like startup and project information retrieval within Evidently.",advanced,code,faq/telemetry.mdx
evidently ai platform features overview,"The article outlines the comprehensive feature set of the Evidently Platform, designed to support AI quality workflows with tools for tracing, synthetic data, and rich dashboards.",beginner,text,faq/why_evidently.mdx
how to use evidently for model evaluation,"It details how Evidently provides over 100 built-in evaluations, allowing users to run assessments without preparing metrics from scratch, making the evaluation process straightforward.",beginner,code,faq/why_evidently.mdx
evidently vs other ml tools comparison,"The article discusses how Evidently distinguishes itself by being open-source and offering built-in metrics, unlike many tools that require extensive setup for evaluations.",intermediate,text,faq/why_evidently.mdx
evidently modular architecture example,"It highlights Evidently's modular structure, allowing users to start small with local checks and gradually enhance capabilities without complex setups or lock-ins.",intermediate,code,faq/why_evidently.mdx
Evidently Python library features,Evidently is an open-source Python library that provides over 100 evaluation metrics and a testing API for evaluating AI systems.,beginner,text,introduction.mdx
how to use Evidently for ML monitoring,"The article outlines steps to use Evidently for monitoring machine learning data quality and drift, emphasizing quick setup.",beginner,code,introduction.mdx
Evidently Cloud platform capabilities,"Evidently Cloud offers a comprehensive toolkit for AI testing and observability, including tools for dataset management and collaboration.",intermediate,text,introduction.mdx
setup evaluation with Evidently,You can run your first evaluation with Evidently in just a few minutes using the provided examples.,beginner,code,introduction.mdx
best practices for using Evidently,The article includes best practices for maintaining reliable AI products through the use of Evidently's tools and features.,intermediate,text,introduction.mdx
Evidently code examples,The Evidently documentation provides an extensive cookbook with end-to-end code tutorials and examples to help users implement evaluations.,intermediate,code,introduction.mdx
integration of Evidently with AI systems,"Evidently is designed to integrate seamlessly with various AI systems, ensuring quality evaluations and monitoring.",advanced,text,introduction.mdx
Evidently metrics overview,You can browse a catalogue of 100+ evaluation metrics provided by Evidently to assess your AI systems effectively.,beginner,text,introduction.mdx
tracing in Evidently Cloud,The Cloud platform includes tracing features to help monitor AI-powered applications and ensure data integrity.,intermediate,text,introduction.mdx
Evidently no-code interface,There is a no-code interface in Evidently Cloud designed for domain experts to collaborate on testing AI quality.,intermediate,text,introduction.mdx
row-level text evaluations,"The article provides a thorough reference for row-level text evaluations, including various evaluation methods and their applications.",beginner,text,metrics/all_descriptors.mdx
exact match descriptor example,"It lists and explains the ExactMatch() function, which checks if the contents of a column match between two specified columns.",beginner,code,metrics/all_descriptors.mdx
pattern matching evaluations,"Describes multiple deterministic evaluations focused on pattern matching within text data, like ExactMatch and RegExp.",beginner,text,metrics/all_descriptors.mdx
syntax validation functions,"The article outlines several syntax validation functions such as IsValidJSON() and IsValidPython(), demonstrating how to ensure data structure integrity.",intermediate,code,metrics/all_descriptors.mdx
text length evaluation,"It describes the TextLength() function which measures the length of text in symbols, an important metric for text evaluations.",beginner,code,metrics/all_descriptors.mdx
parameters for Contains() function,"Provides detailed information on the parameters required for the Contains() function, which checks if text includes specific items.",intermediate,text,metrics/all_descriptors.mdx
JSON validation in data,"Explains the use of IsValidJSON() for validating whether text conforms to JSON format, ensuring data is correctly structured.",intermediate,code,metrics/all_descriptors.mdx
custom Python descriptor,"Describes the CustomDescriptor() function that allows users to implement their own checks in Python, providing flexibility in evaluations.",advanced,code,metrics/all_descriptors.mdx
detecting PII in text,"Lists the PIILLMEval() function which detects Personally Identifiable Information in text, useful for compliance and privacy.",intermediate,code,metrics/all_descriptors.mdx
BERTScore for text similarity,Explains how to utilize the BERTScore() function to calculate similarity between text columns based on token embeddings.,intermediate,code,metrics/all_descriptors.mdx
evaluation metrics for LLM,"Details various LLM evaluation metrics, including CompletenessLLMEval() and NegativityLLMEval(), focusing on language model output.",intermediate,text,metrics/all_descriptors.mdx
IncludesWords function parameters,"Explains the parameters of IncludesWords(), which checks if text contains specified vocabulary words, making it useful for content checks.",intermediate,code,metrics/all_descriptors.mdx
text statistics overview,The article provides an overview of text statistics methods like WordCount() and SentenceCount() for evaluating textual data.,beginner,text,metrics/all_descriptors.mdx
custom check descriptors,"Details how to create custom descriptors for evaluations, giving examples of how to implement specific checks in data.",advanced,code,metrics/all_descriptors.mdx
using RegExp for evaluations,Explains the use of RegExp() to match text against a specified regular expression for validation purposes in evaluations.,intermediate,code,metrics/all_descriptors.mdx
validating SQL syntax,"Lists the IsValidSQL() function, which validates if submitted SQL queries are syntactically correct without executing them.",intermediate,code,metrics/all_descriptors.mdx
what is ContextRelevance?,Describes the ContextRelevance() function which checks if the context is relevant to a given question using semantic similarity.,intermediate,text,metrics/all_descriptors.mdx
Detecting toxicity in text,"Details functions like ToxicityLLMEval() that assess whether the text contains toxic elements, aiding in filtering harmful content.",intermediate,code,metrics/all_descriptors.mdx
using LLM judge parameters,"Explains how to configure LLM judge parameters for custom evaluations, including aliases and models.",advanced,text,metrics/all_descriptors.mdx
out-of-vocabulary words percentage,"Discusses the OOVWordsPercentage() function, which calculates the percentage of out-of-vocabulary words in the text.",beginner,code,metrics/all_descriptors.mdx
text evaluation functions list,"The article provides a complete list of functions available for text evaluations, detailing their roles and use cases.",beginner,text,metrics/all_descriptors.mdx
NegativityLLMEval example,"It gives an example of using NegativityLLMEval() which evaluates the negativity of text, providing essential feedback on language sentiment.",intermediate,code,metrics/all_descriptors.mdx
how to implement SemanticSimilarity,Describes how to use the SemanticSimilarity() function to calculate pairwise similarity scores between text columns.,advanced,code,metrics/all_descriptors.mdx
what is sentence count evaluation?,"The SentenceCount() function is discussed, which provides an absolute count of sentences in a given text for analysis purposes.",beginner,code,metrics/all_descriptors.mdx
detecting bias in language models,"It expands on BiasLLMEval() which identifies biased content within text, critical for ethical evaluations in language processing.",advanced,code,metrics/all_descriptors.mdx
all metrics overview,"The article provides a comprehensive reference for dataset-level evaluations, detailing various metrics, their descriptions, parameters, and test defaults.",beginner,text,metrics/all_metrics.mdx
text evaluation metrics,"It covers text evaluation metrics such as TextEvals() and ValueStats(), explaining their usage and parameters.",beginner,text,metrics/all_metrics.mdx
how to use ValueStats in metrics,ValueStats() aggregates descriptor results and provides descriptive statistics for specified columns in the dataset.,intermediate,code,metrics/all_metrics.mdx
understanding Test Defaults,"The article explains the default test conditions applied when invoking Tests with metrics, including reference-based and fixed heuristics.",beginner,text,metrics/all_metrics.mdx
ColumnCount metric,"ColumnCount() counts the number of columns in a dataset, providing important data quality information.",intermediate,code,metrics/all_metrics.mdx
dataset quality metrics,"The article provides metrics for assessing dataset quality, including counts of missing values and duplicates.",beginner,text,metrics/all_metrics.mdx
examples of data quality metrics,It includes examples such as MissingValueCount() and DuplicatedRowCount() for evaluating data quality within datasets.,intermediate,code,metrics/all_metrics.mdx
how to interpret MeanValue result,MeanValue() computes the mean value of a numerical column and returns the result for analysis of central tendency.,beginner,text,metrics/all_metrics.mdx
category metrics explanation,"It discusses CategoryCount() for counting occurrences of specific categories within columns, enhancing data analysis.",intermediate,text,metrics/all_metrics.mdx
Precision and Recall metrics,The article details Precision() and Recall() metrics used in classification tasks to measure the correctness of predictions.,intermediate,text,metrics/all_metrics.mdx
calculating PrecisionTopK,"PrecisionTopK() computes precision at the top K retrieved items, relevant for evaluating ranking performance.",advanced,code,metrics/all_metrics.mdx
Difference between Recall and Precision,"It clarifies the difference between Recall and Precision, essential metrics for evaluating classification models.",intermediate,text,metrics/all_metrics.mdx
how to apply Test conditions in metrics,The article outlines how to apply test conditions within individual metrics to validate model performance against expected results.,advanced,code,metrics/all_metrics.mdx
Metrics cookbook example,The article refers to a metrics cookbook for practical examples on how to implement various evaluation metrics in datasets.,beginner,code,metrics/all_metrics.mdx
data drift metrics,Data drift metrics are covered to aid in detecting discrepancies in data distributions over time.,intermediate,text,metrics/all_metrics.mdx
explore Classification metrics,"The content delves into various classification metrics including Accuracy(), Precision(), and F1Score() for evaluation tasks.",intermediate,code,metrics/all_metrics.mdx
Dummies model quality metrics,Dummy model quality metrics provide a baseline for assessing model performance against random guesses.,beginner,text,metrics/all_metrics.mdx
R2Score metric uses,"R2Score() is used to calculate the coefficient of determination, indicating how well data points fit a statistical model.",advanced,code,metrics/all_metrics.mdx
how to configure metrics in reporting,The article describes how to use metrics within reporting functions to evaluate dataset quality and model performance.,intermediate,code,metrics/all_metrics.mdx
comparing model quality,It gives guidance on comparing model performance metrics against a baseline or dummy model to assess improvement.,intermediate,text,metrics/all_metrics.mdx
usage of DummyMeanError,"DummyMeanError() calculates mean error for a baseline dummy model, assisting in understanding model performance.",advanced,code,metrics/all_metrics.mdx
data quality checking metrics,Several metrics are outlined for checking data quality through dataset evaluations such as ColumnCount() and EmptyRowsCount().,beginner,text,metrics/all_metrics.mdx
explain DatasetStats(),DatasetStats() gathers essential dataset-level statistics like missing values and column types for quick evaluations.,beginner,text,metrics/all_metrics.mdx
column-level metrics,"Column-level metrics measure specific attributes of dataset columns, such as UniqueValueCount() and MaxValue().",intermediate,text,metrics/all_metrics.mdx
how to find outliers in data,"Using OutRangeValueCount(), you can identify outliers in dataset columns based on set ranges.",advanced,code,metrics/all_metrics.mdx
comparing model accuracy against dummy,Model accuracy is compared to a dummy model to ensure that the predictive system performs better than random chance.,intermediate,text,metrics/all_metrics.mdx
how to implement R2 in regression,"R2Score() implementation in regression metrics assesses model fit, crucial for regression analysis.",advanced,code,metrics/all_metrics.mdx
understanding data calibration metrics,It discusses the importance of data calibration metrics in ensuring data quality over time and across distributions.,intermediate,text,metrics/all_metrics.mdx
best practices for dataset evaluations,"Best practices for conducting dataset evaluations, such as applying appropriate metrics and test conditions effectively, are addressed.",beginner,text,metrics/all_metrics.mdx
Role of Test Defaults in metrics,"Test defaults provide baseline conditions for evaluating metrics, critical to understanding expected model performance.",beginner,text,metrics/all_metrics.mdx
RegressionDummyQuality example,The article provides an example of how to use RegressionDummyQuality to evaluate regression models against dummy predictions.,intermediate,code,metrics/all_metrics.mdx
error measurement metrics,Various error measurement metrics like MAE and RMSE help assess the accuracy of regression models.,intermediate,text,metrics/all_metrics.mdx
metrics for directory structure,It explains the importance of maintaining a coherent structure for metrics to ensure easy accessibility and clarity in evaluations.,beginner,text,metrics/all_metrics.mdx
when to use dataset quality metrics,Dataset quality metrics should be used during preprocessing stages to identify data issues before model training.,beginner,text,metrics/all_metrics.mdx
detection of data drift,"Techniques for detecting data drift are summarized, including the metrics and methods applicable to analyze drift effectively.",intermediate,text,metrics/all_metrics.mdx
charts and visualizations in metrics,The article emphasizes the need for charts and visualizations in metric reporting to better interpret results.,beginner,text,metrics/all_metrics.mdx
example of PrecisionByLabel,PrecisionByLabel() allows evaluation of precision metrics for each class in a multiclass classification problem.,advanced,code,metrics/all_metrics.mdx
how to apply R2 metrics,"R2 metrics are applicable in evaluating regression accuracy, providing insights into model outcomes and performance expectations.",advanced,code,metrics/all_metrics.mdx
available presets for dataset evaluation,"The article lists various pre-built Presets that simplify dataset evaluations, making it easier for users to start without extensive setup.",beginner,text,metrics/all_presets.mdx
how to use text evaluation presets,"It provides guidance on using presets focused on text evaluations and LLM assessments, ideal for those looking to implement predefined metrics quickly.",intermediate,code,metrics/all_presets.mdx
data drift detection preset,"The article details a specific preset for detecting data distribution drift, useful for ensuring the quality and relevance of datasets over time.",beginner,text,metrics/all_presets.mdx
classification preset implementation example,"It includes examples of how to apply the classification presets for evaluating quality in classification tasks, catering to users looking for practical implementation.",advanced,code,metrics/all_presets.mdx
customize data drift detection methods,The article details how to change data drift detection methods and conditions based on column types and dataset characteristics.,beginner,text,metrics/customize_data_drift.mdx
override default data drift algorithm,You can override the default data drift algorithm by passing custom parameters to the chosen Metric or Preset.,beginner,code,metrics/customize_data_drift.mdx
data drift detection thresholds,The article describes how to set thresholds for each drift detection method to customize the drift evaluation process.,intermediate,code,metrics/customize_data_drift.mdx
create custom data drift method,Instructions on how to implement your own custom drift detection method using the StatTest class are provided in the article.,advanced,code,metrics/customize_data_drift.mdx
percentage of drifting columns for dataset drift,You can specify the share of drifting columns that indicates dataset drift using the `drift_share` parameter in the metrics or presets.,intermediate,code,metrics/customize_data_drift.mdx
available methods for data drift,"The article lists over twenty methods available for detecting data drift, including PSI and K-S tests, along with their applicable conditions.",beginner,text,metrics/customize_data_drift.mdx
set thresholds for categorical columns in data drift,You can set thresholds for categorical columns by using parameters like `cat_threshold` when creating a DataDriftPreset.,intermediate,code,metrics/customize_data_drift.mdx
data drift preset example,An example is provided showing how to set up a DataDriftPreset with specific drift share and method parameters.,beginner,code,metrics/customize_data_drift.mdx
difference between drift methods,"The article explains the difference between various drift detection methods, including their conditions and thresholds for detecting drift.",intermediate,text,metrics/customize_data_drift.mdx
python example for customizing data drift,The article includes a Python code snippet that demonstrates how to customize data drift detection with specific functions and parameters.,advanced,code,metrics/customize_data_drift.mdx
apply data drift methods per column,You can apply specific drift methods directly to individual columns using the `per_column_method` parameter in your reports.,intermediate,code,metrics/customize_data_drift.mdx
how to use ValueDrift and DriftedColumnsCount,The article explains how to use ValueDrift and DriftedColumnsCount metrics in your reports for data drift detection.,beginner,code,metrics/customize_data_drift.mdx
implementing custom statistical tests for drift,Instructions are provided on implementing a custom statistical test using the StatTest class and how to register it for drift detection.,advanced,code,metrics/customize_data_drift.mdx
how to map column types for data definition,The article mentions that understanding data definitions and mapping column types is essential for customizing data drift detection effectively.,beginner,text,metrics/customize_data_drift.mdx
detecting text data drift,"The article provides methods specifically for detecting drift in text data, including various statistical techniques appropriate for text analysis.",intermediate,text,metrics/customize_data_drift.mdx
drift detection metrics overview,"A summary of different drift detection metrics and their applications is included, such as K-S test and chi-square test for various data types.",beginner,text,metrics/customize_data_drift.mdx
create custom text evaluator in Evidently,"The article provides a guide on implementing custom row-level text evaluators in Evidently, including code examples for defining custom descriptors.",beginner,code,metrics/customize_descriptor.mdx
Evidently custom column descriptor example,"You can find a detailed example of how to define a `CustomColumnDescriptor` to evaluate dataset columns based on specific criteria, illustrated with Python code.",intermediate,code,metrics/customize_descriptor.mdx
what is a CustomDescriptor in Evidently,"The article explains the concept of `CustomDescriptor` in Evidently, highlighting its use for evaluating multiple dataset columns and returning transformed results.",advanced,text,metrics/customize_descriptor.mdx
HuggingFace models usage examples,"The article explains how to download and use HuggingFace models for text evaluation, offering ready-to-use descriptors and a general interface for custom models.",beginner,code,metrics/customize_hf_descriptor.mdx
How to score text with HuggingFace,"It outlines the procedure for scoring text using HuggingFace models, including sample data creation and usage of different descriptors.",beginner,code,metrics/customize_hf_descriptor.mdx
Implementing custom evaluators with HuggingFace,"The article discusses how to define custom evaluators using the HuggingFace descriptor, providing examples for various emotion classifications.",intermediate,code,metrics/customize_hf_descriptor.mdx
Available descriptors in HuggingFace,"The content lists available built-in descriptors for HuggingFace models, helping users choose appropriate evaluators for their text data.",beginner,text,metrics/customize_hf_descriptor.mdx
Understanding HuggingFace toxicity model,"It details the specific use of the HuggingFaceToxicity model for evaluating toxicity levels in text, including required parameters and implementation examples.",intermediate,code,metrics/customize_hf_descriptor.mdx
Using HuggingFace for emotion classification,"The article provides an example of using HuggingFace for emotion classification, with details on the required parameters and expected results.",beginner,code,metrics/customize_hf_descriptor.mdx
Code for zero-shot classification with HuggingFace,"It explains how to implement zero-shot classification using HuggingFace, providing a code example for clarity.",intermediate,code,metrics/customize_hf_descriptor.mdx
Sample data for HuggingFace evaluation,"The article includes a section on generating toy data for testing HuggingFace models, helping beginners understand how to prepare data for evaluation.",beginner,code,metrics/customize_hf_descriptor.mdx
HuggingFace text detection capabilities,"It describes how to use HuggingFace for text detection, particularly focusing on detecting GPT-2 generated text and relevant parameters.",advanced,code,metrics/customize_hf_descriptor.mdx
Evaluating text data with HuggingFace models,"The article provides a conceptual overview of using HuggingFace models to evaluate various aspects of text data, suitable for users new to the topic.",beginner,text,metrics/customize_hf_descriptor.mdx
using LLM judges in Evidently,"The article provides guidance on how to configure LLM judges in Evidently, including using built-in evaluators and custom templates for evaluation criteria.",beginner,text,metrics/customize_llm_judge.mdx
installing Evidently for LLM evaluation,The article assumes the user has pre-requisites for using Evidently descriptors but does not cover installation. It's recommended to check the official documentation for setup instructions.,beginner,text,metrics/customize_llm_judge.mdx
custom criteria LLM evaluation example,"The article describes how to create custom LLM evaluators using binary and multi-class classification templates, including specific code examples.",intermediate,code,metrics/customize_llm_judge.mdx
LLM based descriptors in Python,The article shows how to import and utilize LLM-based descriptors in Python for evaluating text data with examples included.,beginner,code,metrics/customize_llm_judge.mdx
set up OpenAI API key for LLM,"Users can set up their OpenAI API key as an environment variable, as explained in the article, which is required for LLM evaluation.",beginner,code,metrics/customize_llm_judge.mdx
using built-in LLM evaluators,"The article outlines the available built-in evaluators in Evidently, which can be used to assess criteria like toxicity and contextual quality.",intermediate,text,metrics/customize_llm_judge.mdx
Evidently multiple column evaluation,The article provides examples of how to run evaluations that require multiple columns for accurate assessment in Evidently.,intermediate,code,metrics/customize_llm_judge.mdx
change LLM model in Evidently,"The article includes information on how to switch the default LLM model to another option, such as using different API providers or models.",advanced,text,metrics/customize_llm_judge.mdx
Evidently ToxicityLLMEval usage,The article shares an example of how to use the ToxicityLLMEval descriptor to evaluate text for toxicity in a single-column input.,beginner,code,metrics/customize_llm_judge.mdx
evaluate response fidelity LLM,It explains how to evaluate the fidelity of responses against the context using a custom binary classification template with provided code examples.,advanced,code,metrics/customize_llm_judge.mdx
parameters for LLMEval in Evidently,"The article details various parameters available for LLMEval, helping users customize their evaluation setup in Evidently.",intermediate,text,metrics/customize_llm_judge.mdx
using custom templates with LLM,The article explains how to create and apply custom prompt templates to evaluate specific criteria for text data using LLM.,intermediate,code,metrics/customize_llm_judge.mdx
Evidently Dataset from Pandas,"To generate a Dataset object from a Pandas DataFrame, users can follow the example provided in the article that outlines the integration with Evidently.",beginner,code,metrics/customize_llm_judge.mdx
importance of column names in LLM evaluation,The article emphasizes how defining aliases for column names impacts the results returned by the LLM evaluations in Evidently.,intermediate,text,metrics/customize_llm_judge.mdx
audio quality analysis with LLM,"While the article does not directly cover audio quality, it discusses evaluating context quality and responses which could apply to audio features in a theoretical setup.",advanced,text,metrics/customize_llm_judge.mdx
how to define evaluation criteria in LLM,"It provides a guide on setting evaluation criteria using binary and multiclass classification templates, including detailed coding examples.",intermediate,code,metrics/customize_llm_judge.mdx
environment setup for Evidently LLM,A brief overview is given on setting up the environment variables required for API access when configuring LLM judges in Evidently.,beginner,text,metrics/customize_llm_judge.mdx
LLM Hallucination detection,The article includes an example of how to set up a binary classification template to detect hallucinated responses from an LLM based on the context provided.,advanced,code,metrics/customize_llm_judge.mdx
Evidently's supported LLM providers,The article discusses various LLM providers supported in Evidently and how to select and switch between them.,advanced,text,metrics/customize_llm_judge.mdx
evaluating context in LLM applications,"It discusses how to assess context quality in text outputs, providing examples of how to implement these evaluations in code.",intermediate,code,metrics/customize_llm_judge.mdx
LLMEval integrations in Python,The article covers examples of how to integrate LLMEval descriptors within a Python workflow for evaluating text data.,intermediate,code,metrics/customize_llm_judge.mdx
API key management in Evidently,"It mentions best practices for securely managing API keys, which is crucial for safe access to LLMs.",beginner,text,metrics/customize_llm_judge.mdx
best practices for using LLMs,"The article provides insights on optimal usage of LLMs within Evidently, including correct implementations and avoiding common pitfalls.",advanced,text,metrics/customize_llm_judge.mdx
create custom metric in Evidently,"The article provides a step-by-step guide on creating custom metrics in Evidently, including required implementations and optional visualizations.",beginner,code,metrics/customize_metric.mdx
custom metric example implementation,"An example implementation of a custom metric, `MyMaxMetric`, is included, showing how to calculate the maximum value in a column using Python code.",intermediate,code,metrics/customize_metric.mdx
Evidently custom metrics guide,"This article serves as a comprehensive guide for implementing custom metrics in Evidently, touching on both necessary calculations and optional visualizations.",beginner,text,metrics/customize_metric.mdx
advanced custom metric visualization with Plotly,The article discusses customizing metric visualizations using Plotly and assumes familiarity with the codebase for advanced implementations.,advanced,code,metrics/customize_metric.mdx
classification metrics explained,"The article explains various classification metrics including accuracy, precision, and recall, highlighting their importance for model evaluation.",beginner,text,metrics/explainer_classification.mdx
How to calculate F1-score,"It outlines how to compute the F1-score and its significance in assessing model performance, especially in imbalanced datasets.",intermediate,code,metrics/explainer_classification.mdx
ROC curve definition and purpose,The article defines the ROC curve and explains its use in visualizing the tradeoff between true positive rates and false positive rates at various thresholds.,beginner,text,metrics/explainer_classification.mdx
visualize confusion matrix in Python,It provides code examples for visualizing confusion matrices using accompanied charts to help analyze classification errors.,intermediate,code,metrics/explainer_classification.mdx
importance of precision-recall curve,The article elaborates on the precision-recall curve and its relevance in understanding the balance between precision and recall for different classification thresholds.,beginner,text,metrics/explainer_classification.mdx
using Evidently for model evaluation,The document explains how to utilize Evidently's tools for conducting thorough model performance analysis and generating reports.,intermediate,code,metrics/explainer_classification.mdx
class representation in classification metrics,"The article discusses how class representation metrics can illustrate the distribution of objects across different classes, aiding in performance analysis.",beginner,text,metrics/explainer_classification.mdx
advanced metrics for model quality,It touches on advanced concepts like quality metrics by class and how to leverage them for detailed model assessments.,advanced,text,metrics/explainer_classification.mdx
dataset overview statistics,"The article provides insights into dataset overviews, highlighting missing features and general information essential for assessing data quality.",beginner,text,metrics/explainer_data_stats.mdx
feature visualizations in data quality,"This section details how feature widgets visualize data, showing statistical summaries and distributions for various feature types including categorical and numerical.",beginner,code,metrics/explainer_data_stats.mdx
missing values percentage in dataset,The article explains how to identify missing values in datasets and their implications for data quality assessments.,beginner,text,metrics/explainer_data_stats.mdx
numerical feature distribution visualization,"The article illustrates how numerical features can be visualized for better understanding of their distribution within a dataset, helping to identify patterns and outliers.",intermediate,code,metrics/explainer_data_stats.mdx
categorical feature analysis,It offers insights into analyzing categorical features through specific visualizations that help in understanding their relationships with other variables.,intermediate,code,metrics/explainer_data_stats.mdx
correlation between features,"This part of the article discusses how correlation widgets analyze relationships between different features, providing insights that can affect decision-making.",advanced,text,metrics/explainer_data_stats.mdx
how to visualize quality metrics in Evidently,"The article provides examples of how to implement visualizations for quality metrics using Evidently, showcasing multiple widget functionalities.",advanced,code,metrics/explainer_data_stats.mdx
data drift detection methods,"The article explains various methods for detecting data drift, including statistical tests that compare distributions between datasets.",beginner,text,metrics/explainer_drift.mdx
how to detect data drift in datasets,Evidently compares distributions of two datasets to detect data drift using various statistical tests based on column types.,beginner,code,metrics/explainer_drift.mdx
Evidently data drift examples,The article includes examples of how to implement data drift detection using Evidently's library for various data types.,intermediate,code,metrics/explainer_drift.mdx
default drift detection logic,It details the default logic used by Evidently for choosing appropriate drift detection tests depending on column characteristics.,intermediate,text,metrics/explainer_drift.mdx
drift detection for categorical data,The article specifically outlines how Evidently applies tests like the chi-squared test for categorical columns to detect drift.,intermediate,code,metrics/explainer_drift.mdx
requirements for data drift analysis,"To analyze data drift, two non-empty datasets must be provided: one as a reference and the other as current, as explained in the article.",beginner,text,metrics/explainer_drift.mdx
statistical tests for data drift,The article highlights specific statistical tests such as the Kolmogorov-Smirnov test and Wasserstein Distance used for various data conditions.,advanced,code,metrics/explainer_drift.mdx
ROC AUC for text data drift,"It describes how the ROC AUC score of a domain classifier is used to detect drift in text data, with specific thresholds for large and small datasets.",advanced,code,metrics/explainer_drift.mdx
Recall at K definition,"Recall at K measures the proportion of relevant items retrieved in the top K results, helping assess a recommendation system's effectiveness.",beginner,text,metrics/explainer_recsys.mdx
How to compute Precision at K,"Precision at K is calculated by finding the ratio of relevant items in the top K results to the total items in that top K, indicating the relevance of suggestions made by the system.",beginner,code,metrics/explainer_recsys.mdx
F Beta score explained,"The F Beta score at K combines precision and recall into one metric, allowing for a balanced evaluation of a recommender system's performance based on user preferences.",intermediate,text,metrics/explainer_recsys.mdx
Mean Average Precision calculation sample,Mean Average Precision (MAP) at K is computed by averaging the precision scores of all relevant items in the top K results across all users or queries.,intermediate,code,metrics/explainer_recsys.mdx
What is NDCG and its importance,"NDCG (Normalized Discounted Cumulative Gain) is a metric that evaluates the ranking quality by comparing the actual ranked list to an ideal ordering of items, emphasizing the importance of position.",beginner,text,metrics/explainer_recsys.mdx
Hit Rate evaluation method,"Hit Rate measures the proportion of users for whom at least one relevant item is included in the top K results, indicating how well the system meets user needs.",intermediate,code,metrics/explainer_recsys.mdx
How to use MAR in evaluations,Mean Average Recall (MAR) measures the retrieval effectiveness across multiple users by averaging recall scores at relevant positions within the top K results.,intermediate,code,metrics/explainer_recsys.mdx
Understanding Score Distribution in recsys,"Score Distribution evaluates the entropy of predicted item scores, providing insight into the diversity of the recommendations made by the system.",advanced,text,metrics/explainer_recsys.mdx
Examples of ranking metrics in recommender systems,"Ranking metrics such as Recall, Precision, and MAP are critical for assessing how effectively a recommendation system performs in returning relevant results.",beginner,text,metrics/explainer_recsys.mdx
MRR calculation formula,"Mean Reciprocal Rank (MRR) calculates the average rank position of the first relevant item in recommendation lists, providing insight into ranking quality.",intermediate,code,metrics/explainer_recsys.mdx
mean absolute error calculation,The article explains how to calculate Mean Absolute Error (MAE) as part of standard model quality metrics in regression analysis.,beginner,code,metrics/explainer_regression.mdx
visualization of predicted vs actual values,The article describes how to use scatter plots to visualize the differences between predicted and actual values in regression models.,beginner,code,metrics/explainer_regression.mdx
standard deviation in regression metrics,It discusses how standard deviation is used alongside metrics like Mean Error to assess the stability of model performance.,intermediate,text,metrics/explainer_regression.mdx
error distribution in regression models,"The article provides insights on visualizing the distribution of model error values, which helps in assessing model accuracy.",intermediate,code,metrics/explainer_regression.mdx
how to analyze regression errors,"The article suggests using various plots and metrics to analyze model errors, helping to identify improvement areas.",beginner,text,metrics/explainer_regression.mdx
Q-Q plot for error normality,It covers the use of Q-Q plots to estimate the normality of error distributions in regression output.,advanced,text,metrics/explainer_regression.mdx
calculate absolute percentage error,The article details how to compute Absolute Percentage Error (APE) as part of evaluating regression model accuracy.,beginner,code,metrics/explainer_regression.mdx
error bias per feature analysis,It explains how to visualize error bias for each feature to uncover potential relationships with high error occurrences.,intermediate,code,metrics/explainer_regression.mdx
features affecting regression model accuracy,"The article delves into identifying features that significantly impact regression model accuracy, using error bias tables and plots.",advanced,text,metrics/explainer_regression.mdx
classification quality preset example,"The article includes code examples showing how to implement the ClassificationPreset for evaluating performance metrics on datasets, illustrating its usage with sample code snippets.",beginner,code,metrics/preset_classification.mdx
how to customize classification report,"It describes various ways to customize the classification report, including changing test conditions and modifying report compositions to include additional metrics like Correlations and Data Drift.",intermediate,code,metrics/preset_classification.mdx
classification metrics explained,"The article outlines several key metrics used in classification tasks, such as Accuracy, Precision, Recall, and F1-score, providing an overview of their importance in evaluating model performance.",beginner,text,metrics/preset_classification.mdx
data drift evaluation example,"The article provides a code example on how to evaluate data drift using the DataDriftPreset, showing how to run a report on current and reference datasets.",beginner,code,metrics/preset_data_drift.mdx
how to customize data drift report,"It explains various ways to customize a data drift report, such as selecting specific columns, changing drift detection methods, and modifying thresholds for evaluations.",intermediate,code,metrics/preset_data_drift.mdx
understanding target prediction drift,"The article outlines how the DataDriftPreset evaluates both target and prediction drift, providing insights into shifts in target values alongside feature changes.",beginner,text,metrics/preset_data_drift.mdx
data drift prerequisites,"Before using the DataDriftPreset, users need to know how to prepare data and create reports, which are briefly mentioned in the article as prerequisites.",beginner,text,metrics/preset_data_drift.mdx
advanced data drift methods,"It discusses advanced customization options for drift detection methods, including PSI and K-L divergence, catering to users familiar with data analysis.",advanced,code,metrics/preset_data_drift.mdx
data summary preset usage example,The article provides a code sample on how to utilize the DataSummaryPreset for evaluating a dataset using the Report class.,beginner,code,metrics/preset_data_summary.mdx
how to run data quality tests with data summary,"It explains how to enable tests within the DataSummaryPreset by passing a reference dataset, auto-generating quality tests during evaluation.",intermediate,code,metrics/preset_data_summary.mdx
data summary preset description,"The article outlines the features of the DataSummaryPreset, including its function to visualize key statistics and enable dataset comparisons for quality assessment.",beginner,text,metrics/preset_data_summary.mdx
Recommender Systems Preset functionality,"The article explains how the Recommender Systems Preset evaluates recommendation quality, using multiple metrics to assess ranking and diversity, particularly focusing on the 'k' parameter for Top-K recommendations.",beginner,text,metrics/preset_recsys.mdx
Top-K recommendations example,"The article provides a Python code example to generate a report for Top-K recommendations using the `RecSysPreset`, demonstrating how to run it on current data.",beginner,code,metrics/preset_recsys.mdx
how to run tests in recommender system,It outlines how to include pass/fail tests in the evaluation of a recommender system using the `Ref` dataset to auto-generate performance tests for the recommendations.,intermediate,code,metrics/preset_recsys.mdx
regression preset overview,"The article covers the Regression Quality Preset, explaining how to evaluate model performance using various metrics and visualizations, as well as how to set up reports with tests.",beginner,text,metrics/preset_regression.mdx
how to run regression report example,"It provides code examples for running a regression report using the `RegressionPreset`, either on a single dataset or comparing it with a reference dataset.",beginner,code,metrics/preset_regression.mdx
customize regression report tests,"The article explains how to customize regression report tests and conditions, allowing users to modify metrics and conditions for improved evaluations.",intermediate,code,metrics/preset_regression.mdx
text evals python example,"The article includes code examples for running the Text Evals Preset on datasets using Python, demonstrating how to generate reports and run evaluations.",beginner,code,metrics/preset_text_evals.mdx
how to use descriptors in text evals,"It explains how to compute and add descriptors to your dataset before running evaluations with Text Evals, and includes links to further resources on descriptors.",beginner,text,metrics/preset_text_evals.mdx
advanced text evals customization options,"The document outlines advanced options for customizing reports with Text Evals, including adding various metrics and modifying test conditions.",advanced,code,metrics/preset_text_evals.mdx
evaluate LLM outputs with Evidently,"The article explains how to use Evidently to automatically evaluate LLM outputs for prompts, models, and tests, ensuring faster iterations and reliable results.",beginner,text,quickstart_llm.mdx
Evidently LLM Cloud setup guide,"It provides a step-by-step guide to set up Evidently Cloud, install necessary libraries, and create projects for local or cloud evaluations.",beginner,code,quickstart_llm.mdx
how to run evaluations on LLM outputs,"The article describes how to prepare datasets, run evaluations using various descriptors, and obtain results using the Evidently library.",intermediate,code,quickstart_llm.mdx
Python install Evidently,Instructions are included for installing the Evidently Python library needed for running evaluations on LLM outputs.,beginner,code,quickstart_llm.mdx
creating evaluation reports in Evidently,"The article details how to create and run reports that summarize evaluation results, which can be visualized locally or uploaded to the cloud.",intermediate,code,quickstart_llm.mdx
custom LLM judge implementation,It offers insights on how to implement custom LLM judges using built-in templates to evaluate question appropriateness based on user-defined criteria.,advanced,code,quickstart_llm.mdx
Evidently dashboard tracking evals,Users can learn how to track evaluation results over time using the Evidently dashboard and set up alerts for performance monitoring.,intermediate,text,quickstart_llm.mdx
examples of descriptors for LLM evaluation,The article includes examples of various descriptors like Sentiment and TextLength that can be used to evaluate LLM responses and enhance analysis.,beginner,code,quickstart_llm.mdx
Integrating tests in LLM evaluations,"It explains how to integrate test conditions within evaluations, such as assessing sentiment and text length to determine if outputs meet criteria.",advanced,code,quickstart_llm.mdx
data drift evaluation example,"The article explains how to run a simple data drift evaluation report using Evidently for tabular data, helping to identify shifts in model quality.",beginner,code,quickstart_ml.mdx
how to set up Evidently for data drift,It details the steps to set up your environment and install the Evidently library needed for data drift evaluation.,beginner,code,quickstart_ml.mdx
check prediction quality in ML,"The article discusses evaluating prediction quality, covering aspects like classification accuracy and other metrics to assess model performance.",intermediate,text,quickstart_ml.mdx
install Evidently library,"Installation instructions for the Evidently library are provided, guiding users through the setup process in a Python environment.",beginner,code,quickstart_ml.mdx
generate data drift report in Python,"The article offers a code snippet for generating a data drift report in Python, illustrating how to use the Evidently library effectively for evaluations.",intermediate,code,quickstart_ml.mdx
customize drift tests in Evidently,"A brief mention is made of customizing drift tests, allowing users to adjust methods and thresholds for tailored data evaluations.",advanced,text,quickstart_ml.mdx
setup tracing for LLM app,"The article explains the steps to set up tracing for an LLM application using Tracely and Evidently, including installation and configuration.",beginner,code,quickstart_tracing.mdx
Evidently Cloud examples,It covers how to use Evidently Cloud to view and evaluate traces generated from an LLM application.,beginner,code,quickstart_tracing.mdx
how to install tracely and evidently,The article lists the installation commands for Tracely and Evidently libraries necessary for tracing LLM apps.,beginner,code,quickstart_tracing.mdx
trace event example in Python,This guide includes Python examples for creating and managing trace events using the Tracely library in conjunction with OpenAI.,intermediate,code,quickstart_tracing.mdx
LLM evaluation methods,"The article discusses how to run evaluations on the traced data using Evidently, showcasing different methods and descriptors for analysis.",advanced,text,quickstart_tracing.mdx
create adversarial test dataset,"The article explains how to create your own adversarial test dataset using Evidently Cloud's UI, including selecting scenarios and configuring settings.",beginner,code,synthetic-data/adversarial_data.mdx
adversarial testing scenarios examples,"It provides various examples of adversarial testing scenarios like harmful content, forbidden topics, and prompt leakage that can be configured for testing AI models.",intermediate,text,synthetic-data/adversarial_data.mdx
generate test cases for AI with examples,The article explains how to create test input cases for AI systems by providing descriptions and examples to generate diverse questions for testing.,beginner,code,synthetic-data/input_data.mdx
how to create synthetic inputs for models,It details the steps to generate synthetic inputs specific to your LLM app context by defining scenarios and example inputs.,intermediate,code,synthetic-data/input_data.mdx
testing AI with synthetic inputs,"The article discusses the advantages of using synthetic inputs for testing AI systems, highlighting how they can improve test coverage.",beginner,text,synthetic-data/input_data.mdx
edge cases in synthetic input generation,It describes how to create adversarial inputs by detailing edge cases to test AI model resilience.,advanced,code,synthetic-data/input_data.mdx
using the Evidently UI for test questions,The article provides a guide on using the Evidently UI to start projects and generate input test cases effectively.,beginner,code,synthetic-data/input_data.mdx
generate synthetic test data examples,"The article provides an overview of creating synthetic test inputs for evaluating AI systems, including practical cases such as experiments and regression testing.",beginner,code,synthetic-data/introduction.mdx
create RAG test dataset example,The article provides a step-by-step guide on generating an effective RAG test dataset by uploading a knowledge base and creating user-like questions with ground truth answers.,beginner,code,synthetic-data/rag_data.mdx
synthetic data for AI evaluation,"The article explains how synthetic data can be utilized to create diverse test datasets for evaluating AI systems, particularly when real data is insufficient or difficult to obtain.",beginner,text,synthetic-data/why_synthetic.mdx
how to generate synthetic test datasets,"It details various methods to create synthetic datasets, highlighting their role in enhancing AI evaluation by allowing for quicker and more varied test cases.",intermediate,code,synthetic-data/why_synthetic.mdx
