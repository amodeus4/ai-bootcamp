{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9191fa3-d989-4b0c-be0e-df04dc1c8ac0",
   "metadata": {},
   "source": [
    "## Evaluation retrieval\n",
    "\n",
    "we'll evaluate different search approaches using our synthetic dataset. We'll compare keyword-based search, vector search, and hybrid approaches to see which performs best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c74706e-a1db-41ef-8460-6b875bf6c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a5573d-1274-49a9-a68e-14a609be0ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ground_truth = pd.read_csv('ground_truth_evidently.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "275b583d-7dff-4ba8-b5a2-1af1b5dca5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4b3ba01-2eb8-4c5b-a73a-90cfecb4d51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'data definition in Evidently',\n",
       " 'summary_answer': 'The article describes how to create a `DataDefinition` object to map column types and roles essential for data evaluation in Evidently.',\n",
       " 'difficulty': 'beginner',\n",
       " 'intent': 'text',\n",
       " 'filename': 'docs/library/data_definition.mdx'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec = ground_truth[0]\n",
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c3b244a-b7af-4b47-9c93-bd17e3c086cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docs\n",
    "\n",
    "github_data = docs.read_github_data()\n",
    "parsed_data = docs.parse_data(github_data)\n",
    "chunks = docs.chunk_documents(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c62ccfb-46db-4ef6-a43a-0c6dd5aa7bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x722e92cb7050>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  index the chunked documents\n",
    "from minsearch import Index\n",
    "from typing import Any, Dict, List, TypedDict\n",
    "\n",
    "index = Index(\n",
    "    text_fields=[\"content\", \"filename\", \"title\", \"description\"],\n",
    ")\n",
    "\n",
    "index.fit(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3dfe210-7327-431b-8917-763aaab68e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our baseline search function using keyword-based search\n",
    "class SearchResult(TypedDict):\n",
    "    \"\"\"Represents a single search result entry.\"\"\"\n",
    "    start: int\n",
    "    content: str\n",
    "    title: str\n",
    "    description: str\n",
    "    filename: str\n",
    "\n",
    "\n",
    "def search(query: str) -> List[SearchResult]:\n",
    "    \"\"\"\n",
    "    Search the index for documents matching the given query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query string.\n",
    "\n",
    "    Returns:\n",
    "        List[SearchResult]: A list of search results. Each result dictionary contains:\n",
    "            - start (int): The starting position or offset within the source file.\n",
    "            - content (str): A text excerpt or snippet containing the match.\n",
    "            - title (str): The title of the matched document.\n",
    "            - description (str): A short description of the document.\n",
    "            - filename (str): The path or name of the source file.\n",
    "    \"\"\"\n",
    "    return index.search(\n",
    "        query=query,\n",
    "        num_results=5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00fe5b9-73e3-4d1e-96c2-d02bab99e7c1",
   "metadata": {},
   "source": [
    "## Collecting Search Results for Evaluation\n",
    "Now let's run our search function against all questions in the ground truth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8270ed17-7b32-46d7-ae92-874250d8e835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f072d3b13f4ed5921e2ab0def373c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#run our search function against all questions in the ground truth dataset\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "all_search_results = []\n",
    "\n",
    "for gt_rec in tqdm(ground_truth):\n",
    "    sr = search(gt_rec['question'])\n",
    "    filename = gt_rec['filename']\n",
    "    relevance = [filename == sr_rec['filename'] for sr_rec in sr]\n",
    "    all_search_results.append(relevance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e790919b-04cb-4b50-bb8c-ec20a2c5a366",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "We will implement two search evaluation metrics:\n",
    "- Hit Rate: The percentage of queries where at least one relevant document appears in the top results.\n",
    "- Mean Reciprocal Rank (MRR): The average of reciprocal ranks of the first relevant document. It rewards finding relevant documents early in the result list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26c1b9e4-c726-4f91-975a-a2e67011b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hit rate implementation\n",
    "\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2074b61-9841-438c-aa83-9dd06b392fce",
   "metadata": {},
   "source": [
    "For MRR, we also look at the position:\n",
    "\n",
    "- if the relevant result is at position 1, score is 1\n",
    "- position 2 => 1/2\n",
    "- position 3 => 1/3\n",
    "- position 4 => 1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "895db554-a626-480f-b1fb-25c6b971e8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mrr implementation\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "                break\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a29a9472-eb0b-44db-aa68-448569e33376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put them together\n",
    "\n",
    "def evaluate(\n",
    "        ground_truth,\n",
    "        search_function,\n",
    "        question_column='question',\n",
    "        id_column='filename'\n",
    "):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q[id_column]\n",
    "        results = search_function(q[question_column])\n",
    "        relevance = [d[id_column] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f5c12-a474-444d-b46d-9a5acb06407b",
   "metadata": {},
   "source": [
    "## Baseline Performance Evaluation\n",
    "Let's evaluate our keyword-based search to establish a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f324de88-8094-4a32-a8c6-c4632cae735b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe9713e7e2d4156b937e0ca005be0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.4372384937238494, 'mrr': 0.37036262203626213}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac62bd2-ec49-497e-893f-2af76b12ecdc",
   "metadata": {},
   "source": [
    "## Vector Search Implementation\n",
    "\n",
    "Keyword search struggles with semantic similarity. Let's try vector search, which can understand the meaning behind queries.\n",
    "\n",
    "First, we need to set up the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fbbd452-400a-4ace-9a0b-d23a28ac8ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer('multi-qa-distilbert-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4e7f60a-99a6-483d-a32b-305475be01c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6471e9b0096a4067855cf150ea5e9929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/575 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create embeddings for all document chunks \n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for d in tqdm(chunks):\n",
    "    text = d.get('title', '') + ' ' + d.get('description', '') + ' ' + d.get('content', '')\n",
    "    text = text.strip()\n",
    "    v = embedding_model.encode(text)\n",
    "    embeddings.append(v)\n",
    "\n",
    "embeddings = np.array(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c00ff29-5061-4e00-9afd-e9f461db381b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x722d777e3fe0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index them with vector search \n",
    "\n",
    "from minsearch import VectorSearch\n",
    "\n",
    "vindex = VectorSearch()\n",
    "vindex.fit(embeddings, chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ee157e5-4364-42c8-9700-098c148f915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vector search function\n",
    "\n",
    "def v_search(query: str) -> List[SearchResult]:\n",
    "    \"\"\"\n",
    "    Search the index for documents matching the given query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query string.\n",
    "\n",
    "    Returns:\n",
    "        List[SearchResult]: A list of search results. Each result dictionary contains:\n",
    "            - start (int): The starting position or offset within the source file.\n",
    "            - content (str): A text excerpt or snippet containing the match.\n",
    "            - title (str): The title of the matched document.\n",
    "            - description (str): A short description of the document.\n",
    "            - filename (str): The path or name of the source file.\n",
    "    \"\"\"\n",
    "\n",
    "    q = embedding_model.encode(query)\n",
    "\n",
    "    return vindex.search(\n",
    "        q,\n",
    "        num_results=5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893be869-c7c3-4743-9115-02811541f070",
   "metadata": {},
   "source": [
    "## Vector Search Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48e428dc-1823-441b-89f7-895fb5ed7cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2071f201c843babaa342924ceb366a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.7280334728033473, 'mrr': 0.5702928870292887}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, v_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93f0f6-b9ad-472b-9546-5426bd256fde",
   "metadata": {},
   "source": [
    "## Hybrid Search Approach\n",
    "\n",
    "Can we get even better results by combining both approaches? Let's try a hybrid search that uses both vector and keyword search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69f59c8a-1520-42e0-a1f4-0c843586bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_search(query: str) -> List[SearchResult]:\n",
    "    \"\"\"\n",
    "    Search the index for documents matching the given query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query string.\n",
    "\n",
    "    Returns:\n",
    "        List[SearchResult]: A list of search results. Each result dictionary contains:\n",
    "            - start (int): The starting position or offset within the source file.\n",
    "            - content (str): A text excerpt or snippet containing the match.\n",
    "            - title (str): The title of the matched document.\n",
    "            - description (str): A short description of the document.\n",
    "            - filename (str): The path or name of the source file.\n",
    "    \"\"\"\n",
    "    return v_search(query) + search(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221d1a6d-a2d6-42e0-a29d-21ba54e1b928",
   "metadata": {},
   "source": [
    "## Hybrid Search Evaluation\n",
    "\n",
    "evaluate hybrid approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8aa86f0b-4855-4828-90a3-0ddde68f5965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b495a6e48f74c00bde1140a43213895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_search\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(ground_truth, search_function, question_column, id_column)\u001b[39m\n\u001b[32m     12\u001b[39m     doc_id = q[id_column]\n\u001b[32m     13\u001b[39m     results = search_function(q[question_column])\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     relevance = \u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mid_column\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     15\u001b[39m     relevance_total.append(relevance)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     18\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhit_rate\u001b[39m\u001b[33m'\u001b[39m: hit_rate(relevance_total),\n\u001b[32m     19\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmrr\u001b[39m\u001b[33m'\u001b[39m: mrr(relevance_total),\n\u001b[32m     20\u001b[39m }\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "evaluate(ground_truth, h_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa2c7ed-b918-48de-96c9-9b74456f1945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
