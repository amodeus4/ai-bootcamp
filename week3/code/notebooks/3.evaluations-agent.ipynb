{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6921c0d9-f87f-4b90-bcd8-b5d43a46e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e09b9fb-54d2-47be-a5fb-b501eb375f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import main\n",
    "agent = main.agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "289f2870-f043-4110-9119-f63e035693bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ground_truth = pd.read_csv('ground_truth_evidently.csv')\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9958cca2-ed63-4b6c-8f0c-428069be2be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'column type defaults Evidently', 'summary_answer': 'The article lists default column types applied during automated mapping when no explicit `DataDefinition` is provided, enhancing user understanding.', 'difficulty': 'beginner', 'intent': 'text', 'filename': 'docs/library/data_definition.mdx'}\n"
     ]
    }
   ],
   "source": [
    "q = ground_truth[10]\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97316e68-eefc-42a5-96d5-f461ef370e6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Evidently Column Type Defaults\n",
      "\n",
      "## Column Type Defaults in Evidently\n",
      "\n",
      "In Evidently, column types can be assigned defaults automatically based on the data input, allowing users to run evaluations with minimal configuration. Each column type can have a default inferred from the data provided or be manually specified. The library supports a variety of data types including numerical, categorical, textual, and more, promoting flexible integration with different datasets and evaluation needs. Evaluations in Evidently utilize these column types to assess model performance and data quality effectively.\n",
      "\n",
      "### References\n",
      "\n",
      "- Why Evidently? (https://github.com/evidentlyai/docs/blob/main/faq/why_evidently.mdx)\n",
      "\n",
      "- Evidently Cloud (https://github.com/evidentlyai/docs/blob/main/docs/setup/cloud.mdx)\n",
      "\n",
      "\n",
      "\n",
      "## All References\n",
      "\n",
      "- Why Evidently? (faq/why_evidently.mdx)\n",
      "\n",
      "- Evidently Cloud (docs/setup/cloud.mdx)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test agent with simple question: \n",
    "\n",
    "result = await agent.run(q['question'])\n",
    "print(result.output.format_article())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f8c569-b37d-48fc-b816-a8efdef0e55e",
   "metadata": {},
   "source": [
    "### Preparing Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ff907f-66d4-4ef2-b29b-0226764d7fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 50 questions to work with instead of entire dataset\n",
    "\n",
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "ground_truth_sample = random.sample(ground_truth, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6513aa3b-85c4-4176-96f1-de539ca70402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sample\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('sample.bin', 'wb') as f_out:\n",
    "    pickle.dump(ground_truth_sample, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e41b80-2809-4407-98aa-46a7fec78097",
   "metadata": {},
   "source": [
    "### Error Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e551539-995b-496b-8855-2b40fb0aec7d",
   "metadata": {},
   "source": [
    "The plan is to evaluate the agent against all ground truth data.\n",
    "\n",
    "But what if it breaks while evaluating? It'd be pity if at 80% it breaks with a network error (timeout or something like that), and we need to re-run the whole thing .\n",
    "\n",
    "So let's put things into a try/except block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a01aae8-f356-415e-833b-f17f3bad31c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "async def run_agent(q):\n",
    "    try:\n",
    "        result = await agent.run(q['question'])\n",
    "        return (q, result)\n",
    "    except:\n",
    "        print(f'error processing {q}')\n",
    "        traceback.print_exc()\n",
    "        return (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de45647-990c-4731-9b3e-6858cbe7c64c",
   "metadata": {},
   "source": [
    "### Parallel Processing Setup\n",
    "\n",
    "To efficiently process multiple queries, we'll use asynchronous processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a07cc7b3-ceb4-4060-abd2-1f9f705b1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "async def map_progress(seq, f, max_concurrency=6):\n",
    "    \"\"\"Asynchronously map async function f over seq with progress bar.\"\"\"\n",
    "    semaphore = asyncio.Semaphore(max_concurrency)\n",
    "\n",
    "    async def run(el):\n",
    "        async with semaphore:\n",
    "            return await f(el)\n",
    "\n",
    "    # create one coroutine per element\n",
    "    coros = [run(el) for el in seq]\n",
    "\n",
    "    # turn them into tasks that complete as they finish\n",
    "    completed = asyncio.as_completed(coros)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for coro in tqdm(completed, total=len(seq)):\n",
    "        result = await coro\n",
    "        results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b8f74-e2dc-4b8b-bba1-62eedd0a45fc",
   "metadata": {},
   "source": [
    "### Initial evanuation of sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93c333b1-35fa-4cc3-8612-71695b692628",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559978f4fcd04dc29c1ca3d01e039432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'importance of column names in LLM evaluation', 'summary_answer': 'The article emphasizes how defining aliases for column names impacts the results returned by the LLM evaluations in Evidently.', 'difficulty': 'intermediate', 'intent': 'text', 'filename': 'metrics/customize_llm_judge.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 199808, Requested 243. Please try again in 15ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 199808, Requested 243. Please try again in 15ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'comparison of old and new LLM responses', 'summary_answer': 'The article illustrates processes for comparing LLM outputs before and after changes to assess for significant variations.', 'difficulty': 'intermediate', 'intent': 'text', 'filename': 'examples/LLM_regression_testing.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 196960, Requested 26280. Please try again in 6.972s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 196960, Requested 26280. Please try again in 6.972s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'Evidently Python library examples', 'summary_answer': 'The article provides insights into using the Evidently Python library for running local evaluations and uploading datasets, along with descriptions of its functionalities.', 'difficulty': 'intermediate', 'intent': 'code', 'filename': 'docs/platform/overview.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 191733, Requested 27476. Please try again in 5.762s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 191733, Requested 27476. Please try again in 5.762s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'how to use evidently for model evaluation', 'summary_answer': 'It details how Evidently provides over 100 built-in evaluations, allowing users to run assessments without preparing metrics from scratch, making the evaluation process straightforward.', 'difficulty': 'beginner', 'intent': 'code', 'filename': 'faq/why_evidently.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 187358, Requested 12996. Please try again in 106ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 187358, Requested 12996. Please try again in 106ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'customize drift tests in Evidently', 'summary_answer': 'A brief mention is made of customizing drift tests, allowing users to adjust methods and thresholds for tailored data evaluations.', 'difficulty': 'advanced', 'intent': 'text', 'filename': 'quickstart_ml.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 185369, Requested 15804. Please try again in 351ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 185369, Requested 15804. Please try again in 351ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'automatic column mapping Evidently', 'summary_answer': 'The article details how to use an empty `DataDefinition()` for automatic mapping of columns by type and name when creating a `Dataset` object.', 'difficulty': 'intermediate', 'intent': 'text', 'filename': 'docs/library/data_definition.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 240. Please try again in 72ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 240. Please try again in 72ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'HuggingFace text detection capabilities', 'summary_answer': 'It describes how to use HuggingFace for text detection, particularly focusing on detecting GPT-2 generated text and relevant parameters.', 'difficulty': 'advanced', 'intent': 'code', 'filename': 'metrics/customize_hf_descriptor.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 199777, Requested 242. Please try again in 5ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 199777, Requested 242. Please try again in 5ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'Evidently Dataset setup example', 'summary_answer': 'It provides a step-by-step setup for creating a `Dataset` object using a `DataDefinition`, including code snippets to guide implementation.', 'difficulty': 'beginner', 'intent': 'code', 'filename': 'docs/library/data_definition.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 188068, Requested 12608. Please try again in 202ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 188068, Requested 12608. Please try again in 202ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'using LLM for text evaluation', 'summary_answer': 'You can use built-in LLM-based descriptors to evaluate text and return scores or labels based on external language model outputs.', 'difficulty': 'intermediate', 'intent': 'code', 'filename': 'docs/library/descriptors.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 199533, Requested 13207. Please try again in 3.822s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 199533, Requested 13207. Please try again in 3.822s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'how to set up Evidently for data drift', 'summary_answer': 'It details the steps to set up your environment and install the Evidently library needed for data drift evaluation.', 'difficulty': 'beginner', 'intent': 'code', 'filename': 'quickstart_ml.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 241. Please try again in 72ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 241. Please try again in 72ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'exporting results from descriptors', 'summary_answer': 'Results from evaluations with descriptors can be exported or summarized, allowing for further analysis or reporting.', 'difficulty': 'intermediate', 'intent': 'code', 'filename': 'docs/library/descriptors.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 193975, Requested 13068. Please try again in 2.112s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 193975, Requested 13068. Please try again in 2.112s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'data drift prerequisites', 'summary_answer': 'Before using the DataDriftPreset, users need to know how to prepare data and create reports, which are briefly mentioned in the article as prerequisites.', 'difficulty': 'beginner', 'intent': 'text', 'filename': 'metrics/preset_data_drift.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 12960. Please try again in 3.888s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 12960. Please try again in 3.888s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'text data evaluation descriptors', 'summary_answer': 'Descriptors are a universal interface for evaluating text data, allowing you to compute scores or labels for each row in your dataset.', 'difficulty': 'beginner', 'intent': 'text', 'filename': 'docs/library/descriptors.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 197474, Requested 5779. Please try again in 975ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 197474, Requested 5779. Please try again in 975ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'list of actions tracked in evidently telemetry', 'summary_answer': 'The article lists various actions that are tracked, such as startup, project dashboard views, and report listings to understand feature usage.', 'difficulty': 'intermediate', 'intent': 'text', 'filename': 'faq/telemetry.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 12981. Please try again in 3.894s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 12981. Please try again in 3.894s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'detecting PII in text', 'summary_answer': 'Lists the PIILLMEval() function which detects Personally Identifiable Information in text, useful for compliance and privacy.', 'difficulty': 'intermediate', 'intent': 'code', 'filename': 'metrics/all_descriptors.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 237. Please try again in 71ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 237. Please try again in 71ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'Python code for text descriptors', 'summary_answer': 'The article provides Python code snippets to import necessary modules and create descriptors for evaluating text datasets.', 'difficulty': 'beginner', 'intent': 'code', 'filename': 'docs/library/descriptors.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 240. Please try again in 72ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 200000, Requested 240. Please try again in 72ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'classification quality preset example', 'summary_answer': 'The article includes code examples showing how to implement the ClassificationPreset for evaluating performance metrics on datasets, illustrating its usage with sample code snippets.', 'difficulty': 'beginner', 'intent': 'code', 'filename': 'metrics/preset_classification.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 198984, Requested 16006. Please try again in 4.497s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 198984, Requested 16006. Please try again in 4.497s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'ColumnCount metric', 'summary_answer': 'ColumnCount() counts the number of columns in a dataset, providing important data quality information.', 'difficulty': 'intermediate', 'intent': 'code', 'filename': 'metrics/all_metrics.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 187802, Requested 12862. Please try again in 199ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 187802, Requested 12862. Please try again in 199ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'create custom data drift method', 'summary_answer': 'Instructions on how to implement your own custom drift detection method using the StatTest class are provided in the article.', 'difficulty': 'advanced', 'intent': 'code', 'filename': 'metrics/customize_data_drift.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 197489, Requested 12888. Please try again in 3.113s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 197489, Requested 12888. Please try again in 3.113s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'Evidently Cloud setup for LLM testing', 'summary_answer': 'Instructions are provided for setting up Evidently Cloud and running evaluations using Python and API keys.', 'difficulty': 'beginner', 'intent': 'code', 'filename': 'examples/LLM_regression_testing.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 198841, Requested 13295. Please try again in 3.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 198841, Requested 13295. Please try again in 3.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing {'question': 'using custom templates with LLM', 'summary_answer': 'The article explains how to create and apply custom prompt templates to evaluate specific criteria for text data using LLM.', 'difficulty': 'intermediate', 'intent': 'code', 'filename': 'metrics/customize_llm_judge.mdx'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 487, in _completions_create\n",
      "    return await self.client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 192281, Requested 13436. Please try again in 1.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5950/1768972899.py\", line 5, in run_agent\n",
      "    result = await agent.run(q['question'])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/agent/abstract.py\", line 235, in run\n",
      "    async for node in agent_run:\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/run.py\", line 150, in __anext__\n",
      "    next_node = await self._graph_run.__anext__()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 758, in __anext__\n",
      "    return await self.next(self._next_node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py\", line 731, in next\n",
      "    self._next_node = await node.run(ctx)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 397, in run\n",
      "    return await self._make_request(ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py\", line 439, in _make_request\n",
      "    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 405, in request\n",
      "    response = await self._completions_create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/ai-bootcamp/.venv/lib/python3.12/site-packages/pydantic_ai/models/openai.py\", line 517, in _completions_create\n",
      "    raise ModelHTTPError(status_code=status_code, model_name=self.model_name, body=e.body) from e\n",
      "pydantic_ai.exceptions.ModelHTTPError: status_code: 429, model_name: gpt-4o-mini, body: {'message': 'Rate limit reached for gpt-4o-mini in organization org-rirZkpb1yeMrLusikLcpeFt0 on tokens per min (TPM): Limit 200000, Used 192281, Requested 13436. Please try again in 1.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n"
     ]
    }
   ],
   "source": [
    "all_results = await map_progress(ground_truth_sample, run_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c991f5c7-fbc8-447a-ae8c-4558d3dab2f6",
   "metadata": {},
   "source": [
    "### Processing Results for Analysis\n",
    "\n",
    "When we run it on many queries, we can spot some problems. For example, for some queries the agent is making too many search queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e611ff1c-70dc-4a66-bd5d-b712fa374fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a helper functions to simplify the message structure\n",
    "\n",
    "import json\n",
    "\n",
    "def simplify_messages(messages):\n",
    "    messages_simplified = []\n",
    "\n",
    "    for m in messages:\n",
    "        parts = []\n",
    "\n",
    "        for original_part in m.parts:\n",
    "            kind = original_part.part_kind\n",
    "            # print(original_part)\n",
    "            part = {\n",
    "                'kind': kind\n",
    "            }\n",
    "            if kind == 'user-prompt':\n",
    "                part['content'] = original_part.content\n",
    "            if kind == 'tool-call':\n",
    "                if original_part.tool_name == 'final_result':\n",
    "                    continue\n",
    "    \n",
    "                part['tool_name'] = original_part.tool_name\n",
    "                part['args'] = json.loads(original_part.args)\n",
    "            if kind == 'tool-return':\n",
    "                continue\n",
    "            if kind == 'text':\n",
    "                part['content'] = original_part.content\n",
    "\n",
    "            parts.append(part)\n",
    "\n",
    "        if len(parts) > 0:\n",
    "            messages_simplified.extend(parts)\n",
    "\n",
    "    return messages_simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83b89a5e-67eb-4d72-a136-b5fa81cf4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's count the number of tool calls to understand agent behavior\n",
    "\n",
    "def count_tool_calls(messages):\n",
    "    cnt = 0 \n",
    "    for m in messages:\n",
    "        if m['kind'] == 'tool-call':\n",
    "            cnt = cnt + 1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b5654b4-a2da-4aeb-a36c-9f5f0359b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process all the records\n",
    "\n",
    "def process_result(q, result):\n",
    "    row = {}\n",
    "\n",
    "    row['question'] = q['question']\n",
    "    row['answer'] = result.output.format_article()\n",
    "    row['messages'] = simplify_messages(result.new_messages())\n",
    "    row['num_tool_calls'] = count_tool_calls(row['messages']) \n",
    "\n",
    "    row['original_question'] = q\n",
    "    row['original_result'] = result\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "for q, result in all_results:\n",
    "    if result is None:\n",
    "        continue\n",
    "\n",
    "    row = process_result(q, result)\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ae34333-684c-4237-83fa-760485cd2317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60567f2-a744-4925-84b3-505727b9d3f9",
   "metadata": {},
   "source": [
    "### Identifying Performance Issues\n",
    "\n",
    "During our analysis, we discovered a problem: When it can't find something, it keeps searching and searching.\n",
    "\n",
    "We need to stop it and just explicitly say: \"can't find the information you're asking\". To address it, we'll ask it to limit search to 6 queries. If it can't find anything, then we'll ask it to just say it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5817dba7-257d-408e-8189-7a63f4b22735",
   "metadata": {},
   "source": [
    "### Final Evaluation Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cba03105-f05c-4e28-9ae3-40efcc7c374e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f9f38a8a2e42dd948b69ac9b85d020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_results = await map_progress(ground_truth_sample, run_agent, max_concurrency=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6263c7f-7c0e-44d9-bb28-3accaaec44af",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for q, result in all_results:\n",
    "    if result is None:\n",
    "        continue\n",
    "\n",
    "    row = process_result(q, result)\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb9ade7c-c42a-4c43-9964-9f56b331d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample_eval_rows.bin', 'wb') as f_out:\n",
    "    pickle.dump(rows, f_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
